[2025-03-23T07:31:26.049+0000] {processor.py:161} INFO - Started process (PID=2065) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:31:26.051+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:31:26.053+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:31:26.053+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:31:26.058+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:31:26.057+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:31:26.058+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:31:26.091+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T07:32:06.542+0000] {processor.py:161} INFO - Started process (PID=2072) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:32:06.543+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:32:06.546+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:32:06.546+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:32:06.551+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:32:06.550+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:32:06.552+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:32:06.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.053 seconds
[2025-03-23T07:32:42.248+0000] {processor.py:161} INFO - Started process (PID=2175) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:32:42.251+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:32:42.254+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:32:42.253+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:32:42.259+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:32:42.257+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:32:42.259+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:32:42.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.058 seconds
[2025-03-23T07:33:31.693+0000] {processor.py:161} INFO - Started process (PID=2222) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:33:31.695+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:33:31.698+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:33:31.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:33:31.703+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:33:31.702+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:33:31.703+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:33:31.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T07:34:02.242+0000] {processor.py:161} INFO - Started process (PID=2337) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:34:02.244+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:34:02.249+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:34:02.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:34:02.254+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:34:02.253+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:34:02.255+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:34:02.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.056 seconds
[2025-03-23T07:34:41.886+0000] {processor.py:161} INFO - Started process (PID=2340) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:34:41.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:34:41.891+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:34:41.891+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:34:41.895+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:34:41.894+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:34:41.896+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:34:41.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T07:35:12.384+0000] {processor.py:161} INFO - Started process (PID=2487) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:35:12.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:35:12.388+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:35:12.388+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:35:12.391+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:35:12.390+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:35:12.391+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:35:12.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.037 seconds
[2025-03-23T07:35:46.917+0000] {processor.py:161} INFO - Started process (PID=2543) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:35:46.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:35:46.920+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:35:46.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:35:46.924+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:35:46.923+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:35:46.924+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:35:46.953+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T07:36:26.934+0000] {processor.py:161} INFO - Started process (PID=2560) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:36:26.936+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:36:26.940+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:36:26.939+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:36:26.944+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:36:26.943+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:36:26.944+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:36:26.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T07:37:32.156+0000] {processor.py:161} INFO - Started process (PID=2708) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:37:32.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:37:32.161+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:37:32.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:37:32.164+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:37:32.163+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:37:32.165+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:37:32.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T07:38:07.356+0000] {processor.py:161} INFO - Started process (PID=2794) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:38:07.358+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:38:07.361+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:38:07.360+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:38:07.364+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:38:07.363+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:38:07.365+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:38:07.398+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.048 seconds
[2025-03-23T07:38:22.710+0000] {processor.py:161} INFO - Started process (PID=2843) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:38:22.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:38:22.715+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:38:22.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:38:22.718+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:38:22.717+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:38:22.719+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:38:22.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T07:39:17.317+0000] {processor.py:161} INFO - Started process (PID=2903) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:39:17.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:39:17.322+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:39:17.322+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:39:17.326+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:39:17.325+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:39:17.326+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:39:17.359+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T07:39:52.462+0000] {processor.py:161} INFO - Started process (PID=3006) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:39:52.464+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:39:52.466+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:39:52.466+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:39:52.470+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:39:52.469+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:39:52.470+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:39:52.501+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T07:40:22.765+0000] {processor.py:161} INFO - Started process (PID=3109) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:40:22.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:40:22.769+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:40:22.769+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:40:22.774+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:40:22.773+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:40:22.775+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:40:22.800+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T07:41:01.201+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:41:01.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:41:01.208+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:41:01.207+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:41:01.212+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:41:01.211+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:41:01.213+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:41:01.243+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T07:41:43.079+0000] {processor.py:161} INFO - Started process (PID=148) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:41:43.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:41:43.084+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:41:43.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:41:43.087+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:41:43.086+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:41:43.088+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:41:43.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T07:42:13.938+0000] {processor.py:161} INFO - Started process (PID=210) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:42:13.940+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:42:13.944+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:42:13.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:42:13.947+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:42:13.946+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:42:13.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:42:13.974+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T07:42:52.674+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:42:52.676+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:42:52.680+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:42:52.680+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:42:52.684+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:42:52.683+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:42:52.685+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:42:52.717+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T07:43:23.036+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:43:23.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:43:23.043+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:43:23.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:43:23.047+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:43:23.047+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:43:23.048+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:43:23.076+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T07:44:03.704+0000] {processor.py:161} INFO - Started process (PID=339) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:44:03.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:44:03.708+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:44:03.707+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:44:03.713+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:44:03.712+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:44:03.714+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:44:03.745+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T07:44:34.144+0000] {processor.py:161} INFO - Started process (PID=395) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:44:34.147+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:44:34.150+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:44:34.150+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:44:34.155+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:44:34.154+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:44:34.155+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:44:34.186+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T07:45:04.377+0000] {processor.py:161} INFO - Started process (PID=463) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:45:04.380+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:45:04.383+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:45:04.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:45:04.386+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:45:04.385+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:45:04.387+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:45:04.408+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.036 seconds
[2025-03-23T07:45:42.917+0000] {processor.py:161} INFO - Started process (PID=480) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:45:42.918+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:45:42.920+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:45:42.920+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:45:42.924+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:45:42.923+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:45:42.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:45:42.954+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T07:46:13.105+0000] {processor.py:161} INFO - Started process (PID=646) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:46:13.108+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:46:13.111+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:46:13.111+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:46:13.115+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:46:13.114+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:46:13.115+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:46:13.140+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T07:46:53.237+0000] {processor.py:161} INFO - Started process (PID=670) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:46:53.238+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:46:53.240+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:46:53.240+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:46:53.245+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:46:53.243+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:46:53.245+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:46:53.270+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.038 seconds
[2025-03-23T07:47:33.690+0000] {processor.py:161} INFO - Started process (PID=775) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:47:33.692+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:47:33.695+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:47:33.695+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:47:33.698+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:47:33.698+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:47:33.699+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:47:33.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T07:48:08.443+0000] {processor.py:161} INFO - Started process (PID=837) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:08.445+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:48:08.448+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:48:08.447+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:08.451+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:48:08.450+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:48:08.452+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:08.482+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T07:48:01.749+0000] {processor.py:161} INFO - Started process (PID=893) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:01.751+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:48:01.754+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:48:01.753+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:01.758+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:48:01.757+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:48:01.759+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:01.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T07:48:43.433+0000] {processor.py:161} INFO - Started process (PID=943) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:43.435+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:48:43.438+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:48:43.438+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:43.442+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:48:43.441+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:48:43.443+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:48:43.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T07:49:33.941+0000] {processor.py:161} INFO - Started process (PID=1047) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:49:33.943+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:49:33.945+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:49:33.944+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:49:33.947+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:49:33.947+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:49:33.948+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:49:33.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T07:50:04.725+0000] {processor.py:161} INFO - Started process (PID=1103) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:50:04.727+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:50:04.730+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:50:04.730+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:50:04.734+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:50:04.733+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:50:04.735+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:50:04.763+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T07:50:49.392+0000] {processor.py:161} INFO - Started process (PID=1165) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:50:49.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:50:49.397+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:50:49.396+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:50:49.403+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:50:49.402+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:50:49.403+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:50:49.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.048 seconds
[2025-03-23T07:51:19.820+0000] {processor.py:161} INFO - Started process (PID=1227) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:19.822+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:51:19.825+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:51:19.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:19.829+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:51:19.828+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:51:19.829+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:19.859+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T07:51:21.557+0000] {processor.py:161} INFO - Started process (PID=1250) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:21.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:51:21.564+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:51:21.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:21.569+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:51:21.568+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:51:21.570+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:21.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.048 seconds
[2025-03-23T07:51:51.735+0000] {processor.py:161} INFO - Started process (PID=1300) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:51.737+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:51:51.741+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:51:51.740+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:51.746+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:51:51.744+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:51:51.747+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:51:51.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.060 seconds
[2025-03-23T07:52:33.647+0000] {processor.py:161} INFO - Started process (PID=1345) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:52:33.648+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:52:33.650+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:52:33.650+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:52:33.654+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:52:33.653+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:52:33.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:52:33.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.038 seconds
[2025-03-23T07:53:04.252+0000] {processor.py:161} INFO - Started process (PID=1458) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:53:04.255+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:53:04.257+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:53:04.257+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:53:04.260+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:53:04.259+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:53:04.261+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:53:04.291+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T07:53:43.929+0000] {processor.py:161} INFO - Started process (PID=1463) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:53:43.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:53:43.933+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:53:43.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:53:43.936+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:53:43.935+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:53:43.936+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:53:43.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.034 seconds
[2025-03-23T07:54:14.886+0000] {processor.py:161} INFO - Started process (PID=1567) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:54:14.888+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:54:14.890+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:54:14.890+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:54:14.893+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:54:14.892+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 3, in <module>
    from airflow.providers.google.cloud.transfers.gcs_to_bigquery import GoogleCloudStorageToBigQueryOperator
ImportError: cannot import name 'GoogleCloudStorageToBigQueryOperator' from 'airflow.providers.google.cloud.transfers.gcs_to_bigquery' (/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py)
[2025-03-23T07:54:14.894+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:54:14.926+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T07:54:18.968+0000] {processor.py:161} INFO - Started process (PID=1569) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:54:18.969+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:54:18.971+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:54:18.971+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:54:18.977+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:54:18.977+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GoogleCloudStorageToBigQueryOperator(
NameError: name 'GoogleCloudStorageToBigQueryOperator' is not defined
[2025-03-23T07:54:18.978+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:54:18.999+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.034 seconds
[2025-03-23T07:55:19.166+0000] {processor.py:161} INFO - Started process (PID=1678) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:55:19.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:55:19.172+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:55:19.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:55:19.182+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:55:19.179+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T07:55:19.183+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:55:19.209+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.048 seconds
[2025-03-23T07:56:24.123+0000] {processor.py:161} INFO - Started process (PID=1838) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:56:24.125+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:56:24.128+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:56:24.127+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:56:24.134+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:56:24.133+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T07:56:24.134+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:56:24.161+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T07:57:19.156+0000] {processor.py:161} INFO - Started process (PID=1943) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:57:19.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:57:19.161+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:57:19.161+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:57:19.167+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:57:19.166+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T07:57:19.168+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:57:19.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T07:57:49.810+0000] {processor.py:161} INFO - Started process (PID=2095) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:57:49.812+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:57:49.814+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:57:49.814+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:57:49.820+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:57:49.819+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T07:57:49.821+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:57:49.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T07:58:29.443+0000] {processor.py:161} INFO - Started process (PID=2100) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:58:29.444+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:58:29.447+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:58:29.446+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:58:29.453+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:58:29.451+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T07:58:29.453+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:58:29.476+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.037 seconds
[2025-03-23T07:58:59.674+0000] {processor.py:161} INFO - Started process (PID=2256) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:58:59.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:58:59.679+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:58:59.679+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:58:59.687+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:58:59.685+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T07:58:59.688+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:58:59.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.048 seconds
[2025-03-23T07:59:45.221+0000] {processor.py:161} INFO - Started process (PID=2265) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:59:45.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T07:59:45.224+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:59:45.224+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:59:45.230+0000] {logging_mixin.py:188} INFO - [2025-03-23T07:59:45.228+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T07:59:45.230+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T07:59:45.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:00:20.037+0000] {processor.py:161} INFO - Started process (PID=2321) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:00:20.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:00:20.043+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:00:20.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:00:20.052+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:00:20.050+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:00:20.053+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:00:20.081+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T08:00:50.662+0000] {processor.py:161} INFO - Started process (PID=2377) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:00:50.664+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:00:50.667+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:00:50.667+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:00:50.674+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:00:50.673+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:00:50.675+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:00:50.698+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:01:21.478+0000] {processor.py:161} INFO - Started process (PID=2433) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:21.479+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:01:21.482+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:01:21.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:21.490+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:01:21.488+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:01:21.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:21.521+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T08:01:59.828+0000] {processor.py:161} INFO - Started process (PID=2496) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:59.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:01:59.833+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:01:59.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:59.840+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:01:59.839+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:01:59.841+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:59.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:01:58.180+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:58.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:01:58.184+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:01:58.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:58.190+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:01:58.188+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:01:58.191+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:01:58.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:02:29.190+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:02:29.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:02:29.198+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:02:29.196+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:02:29.211+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:02:29.208+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:02:29.212+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:02:29.247+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.069 seconds
[2025-03-23T08:03:10.006+0000] {processor.py:161} INFO - Started process (PID=147) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:03:10.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:03:10.011+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:03:10.010+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:03:10.017+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:03:10.015+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:03:10.018+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:02:32.650+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:03:03.361+0000] {processor.py:161} INFO - Started process (PID=201) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:03:03.363+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:03:03.366+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:03:03.366+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:03:03.373+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:03:03.371+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:03:03.373+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:03:03.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:03:44.915+0000] {processor.py:161} INFO - Started process (PID=249) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:03:44.916+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:03:44.918+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:03:44.918+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:03:44.925+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:03:44.924+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:03:44.925+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:03:44.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.033 seconds
[2025-03-23T08:04:25.520+0000] {processor.py:161} INFO - Started process (PID=352) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:04:25.522+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:04:25.525+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:04:25.525+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:04:25.533+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:04:25.532+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:04:25.534+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:04:25.554+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:05:00.197+0000] {processor.py:161} INFO - Started process (PID=408) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:05:00.199+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:05:00.202+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:05:00.201+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:05:00.210+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:05:00.208+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:05:00.211+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:04:22.844+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.052 seconds
[2025-03-23T08:04:53.543+0000] {processor.py:161} INFO - Started process (PID=464) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:04:53.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:04:53.548+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:04:53.548+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:04:53.554+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:04:53.553+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:04:53.554+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:04:53.587+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.050 seconds
[2025-03-23T08:05:35.101+0000] {processor.py:161} INFO - Started process (PID=514) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:05:35.102+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:05:35.105+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:05:35.104+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:05:35.116+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:05:35.113+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:05:35.116+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:05:35.148+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.052 seconds
[2025-03-23T08:06:10.256+0000] {processor.py:161} INFO - Started process (PID=617) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:06:10.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:06:10.261+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:06:10.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:06:10.267+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:06:10.266+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:06:10.267+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:06:10.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T08:06:45.307+0000] {processor.py:161} INFO - Started process (PID=720) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:06:45.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:06:45.311+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:06:45.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:06:45.318+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:06:45.316+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:06:45.318+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:06:45.344+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:07:15.491+0000] {processor.py:161} INFO - Started process (PID=866) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:07:15.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:07:15.495+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:07:15.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:07:15.502+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:07:15.501+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:07:15.503+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:07:15.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T08:08:20.496+0000] {processor.py:161} INFO - Started process (PID=922) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:08:20.498+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:08:20.501+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:08:20.501+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:08:20.507+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:08:20.506+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:08:20.508+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:08:20.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.057 seconds
[2025-03-23T08:08:50.958+0000] {processor.py:161} INFO - Started process (PID=1143) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:08:50.960+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:08:50.965+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:08:50.964+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:08:50.971+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:08:50.970+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:08:50.972+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:08:51.003+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T08:09:50.972+0000] {processor.py:161} INFO - Started process (PID=1205) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:09:50.974+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:09:50.977+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:09:50.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:09:50.984+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:09:50.983+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:09:50.985+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:09:51.014+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T08:10:25.784+0000] {processor.py:161} INFO - Started process (PID=1261) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:10:25.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:10:25.790+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:10:25.789+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:10:25.798+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:10:25.796+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:10:25.799+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:10:25.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:11:16.147+0000] {processor.py:161} INFO - Started process (PID=1369) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:11:16.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:11:16.154+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:11:16.154+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:11:16.163+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:11:16.161+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:11:16.164+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:11:16.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:11:46.743+0000] {processor.py:161} INFO - Started process (PID=1425) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:11:46.745+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:11:46.748+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:11:46.747+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:11:46.754+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:11:46.753+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:11:46.755+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:11:46.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.038 seconds
[2025-03-23T08:12:17.142+0000] {processor.py:161} INFO - Started process (PID=1487) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:12:17.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:12:17.147+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:12:17.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:12:17.154+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:12:17.153+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:12:17.154+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:12:17.184+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:12:56.089+0000] {processor.py:161} INFO - Started process (PID=1509) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:12:56.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:12:56.093+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:12:56.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:12:56.099+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:12:56.098+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:12:56.100+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:12:56.125+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T08:13:31.034+0000] {processor.py:161} INFO - Started process (PID=1607) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:13:31.036+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:13:31.041+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:13:31.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:13:31.051+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:13:31.048+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:13:31.051+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:13:31.089+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.061 seconds
[2025-03-23T08:14:36.225+0000] {processor.py:161} INFO - Started process (PID=1761) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:14:36.228+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:14:36.230+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:14:36.230+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:14:36.238+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:14:36.236+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:14:36.239+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:14:36.266+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:15:16.370+0000] {processor.py:161} INFO - Started process (PID=1914) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:15:16.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:15:16.375+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:15:16.374+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:15:16.380+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:15:16.379+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:15:16.381+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:15:16.406+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T08:15:51.295+0000] {processor.py:161} INFO - Started process (PID=2017) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:15:51.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:15:51.299+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:15:51.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:15:51.305+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:15:51.303+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:15:51.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:15:51.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.038 seconds
[2025-03-23T08:16:21.550+0000] {processor.py:161} INFO - Started process (PID=2169) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:16:21.552+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:16:21.558+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:16:21.557+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:16:21.566+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:16:21.564+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:16:21.567+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:16:21.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.064 seconds
[2025-03-23T08:17:16.420+0000] {processor.py:161} INFO - Started process (PID=2180) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:16.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:17:16.426+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:17:16.425+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:16.436+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:17:16.433+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:17:16.437+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:16.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.058 seconds
[2025-03-23T08:17:51.666+0000] {processor.py:161} INFO - Started process (PID=2283) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:51.668+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:17:51.672+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:17:51.671+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:51.681+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:17:51.679+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:17:51.681+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:14.342+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.060 seconds
[2025-03-23T08:17:56.632+0000] {processor.py:161} INFO - Started process (PID=2328) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:56.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:17:56.637+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:17:56.637+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:56.649+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:17:56.647+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:17:56.650+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:56.690+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.066 seconds
[2025-03-23T08:17:54.517+0000] {processor.py:161} INFO - Started process (PID=2411) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:54.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:17:54.526+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:17:54.525+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:54.540+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:17:54.535+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:17:54.541+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:17:54.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.076 seconds
[2025-03-23T08:18:41.575+0000] {processor.py:161} INFO - Started process (PID=2463) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:18:41.576+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:18:41.578+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:18:41.578+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:18:41.586+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:18:41.584+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:18:41.586+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:18:41.618+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T08:19:16.732+0000] {processor.py:161} INFO - Started process (PID=2558) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:16.735+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:19:16.738+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:19:16.737+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:16.746+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:19:16.744+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:19:16.747+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:16.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.050 seconds
[2025-03-23T08:19:47.173+0000] {processor.py:161} INFO - Started process (PID=2783) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:47.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:19:47.180+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:19:47.180+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:47.200+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:19:47.197+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:19:47.202+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:47.240+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.080 seconds
[2025-03-23T08:19:49.342+0000] {processor.py:161} INFO - Started process (PID=2786) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:49.344+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:19:49.346+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:19:49.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:49.352+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:19:49.351+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:19:49.353+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:19:49.374+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.035 seconds
[2025-03-23T08:21:32.258+0000] {processor.py:161} INFO - Started process (PID=2942) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:21:32.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:21:32.261+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:21:32.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:21:32.267+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:21:32.266+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:21:32.267+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:20:54.921+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:21:56.921+0000] {processor.py:161} INFO - Started process (PID=2991) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:21:56.922+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:21:56.925+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:21:56.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:21:56.931+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:21:56.930+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:21:56.932+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:21:56.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:22:42.037+0000] {processor.py:161} INFO - Started process (PID=3091) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:22:42.040+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:22:42.046+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:22:42.045+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:22:42.051+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:22:42.050+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:22:42.052+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:22:42.078+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T08:23:47.254+0000] {processor.py:161} INFO - Started process (PID=3238) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:23:47.256+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:23:47.259+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:23:47.259+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:23:47.269+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:23:47.267+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:23:47.269+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:23:47.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:24:15.113+0000] {processor.py:161} INFO - Started process (PID=3394) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:24:15.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:24:15.118+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:24:15.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:24:15.127+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:24:15.125+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:24:15.128+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:24:15.160+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.055 seconds
[2025-03-23T08:24:45.509+0000] {processor.py:161} INFO - Started process (PID=3443) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:24:45.510+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:24:45.513+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:24:45.513+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:24:45.518+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:24:45.517+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:24:45.518+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:24:45.546+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:25:47.334+0000] {processor.py:161} INFO - Started process (PID=3493) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:25:47.337+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:25:47.340+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:25:47.340+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:25:47.350+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:25:47.348+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:25:47.352+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:25:47.401+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.074 seconds
[2025-03-23T08:26:22.492+0000] {processor.py:161} INFO - Started process (PID=3588) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:26:22.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:26:22.498+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:26:22.497+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:26:22.506+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:26:22.504+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:26:22.507+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:26:22.539+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.053 seconds
[2025-03-23T08:26:52.922+0000] {processor.py:161} INFO - Started process (PID=3737) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:26:52.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:26:52.928+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:26:52.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:26:52.937+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:26:52.935+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:26:52.938+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:26:52.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.054 seconds
[2025-03-23T08:27:32.592+0000] {processor.py:161} INFO - Started process (PID=3741) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:27:32.593+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:27:32.597+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:27:32.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:27:32.604+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:27:32.602+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:27:32.604+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:27:32.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T08:28:22.986+0000] {processor.py:161} INFO - Started process (PID=3935) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:28:22.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:28:22.990+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:28:22.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:28:22.998+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:28:22.997+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:28:22.999+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:28:23.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.048 seconds
[2025-03-23T08:28:53.098+0000] {processor.py:161} INFO - Started process (PID=4088) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:28:53.101+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:28:53.107+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:28:53.106+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:28:53.116+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:28:53.114+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:28:53.116+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:28:53.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.060 seconds
[2025-03-23T08:29:23.447+0000] {processor.py:161} INFO - Started process (PID=4141) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:29:23.449+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:29:23.452+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:29:23.451+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:29:23.458+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:29:23.457+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:29:23.459+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:29:23.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:30:03.054+0000] {processor.py:161} INFO - Started process (PID=4157) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:03.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:30:03.060+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:30:03.059+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:03.068+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:30:03.066+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:30:03.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:03.100+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T08:30:43.207+0000] {processor.py:161} INFO - Started process (PID=4262) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:43.209+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:30:43.211+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:30:43.211+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:43.218+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:30:43.217+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:30:43.218+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:05.894+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.048 seconds
[2025-03-23T08:30:36.165+0000] {processor.py:161} INFO - Started process (PID=4314) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:36.166+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:30:36.171+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:30:36.171+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:36.179+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:30:36.178+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:30:36.180+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:30:36.211+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:31:06.712+0000] {processor.py:161} INFO - Started process (PID=4366) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:06.716+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:31:06.720+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:31:06.720+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:06.729+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:31:06.727+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:31:06.730+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:06.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.057 seconds
[2025-03-23T08:31:48.419+0000] {processor.py:161} INFO - Started process (PID=4416) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:48.420+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:31:48.422+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:31:48.422+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:11.108+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:31:48.431+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:31:11.109+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:11.145+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.057 seconds
[2025-03-23T08:31:53.378+0000] {processor.py:161} INFO - Started process (PID=4459) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:53.379+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:31:53.382+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:31:53.382+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:53.392+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:31:53.389+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:31:53.393+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:31:53.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.056 seconds
[2025-03-23T08:32:48.712+0000] {processor.py:161} INFO - Started process (PID=4751) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:48.715+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:32:48.720+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:32:48.719+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:48.728+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:32:48.726+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:32:48.729+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:11.315+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.060 seconds
[2025-03-23T08:32:53.526+0000] {processor.py:161} INFO - Started process (PID=4801) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:53.528+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:32:53.531+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:32:53.530+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:16.235+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:32:16.233+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:32:16.236+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:16.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.061 seconds
[2025-03-23T08:32:58.193+0000] {processor.py:161} INFO - Started process (PID=4844) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:58.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:32:58.199+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:32:58.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:58.208+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:32:58.206+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:32:58.209+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:32:58.246+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.058 seconds
[2025-03-23T08:33:28.884+0000] {processor.py:161} INFO - Started process (PID=5018) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:33:28.887+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:33:28.892+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:33:28.891+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:33:28.906+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:33:28.900+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:33:28.907+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:33:28.944+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.067 seconds
[2025-03-23T08:34:08.491+0000] {processor.py:161} INFO - Started process (PID=5022) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:08.492+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:34:08.496+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:34:08.495+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:08.505+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:34:08.502+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:34:08.506+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:08.552+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.067 seconds
[2025-03-23T08:34:18.318+0000] {processor.py:161} INFO - Started process (PID=5078) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:18.320+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:34:18.324+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:34:18.323+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:18.335+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:34:18.332+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:34:18.336+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:18.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.061 seconds
[2025-03-23T08:34:48.830+0000] {processor.py:161} INFO - Started process (PID=5177) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:48.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:34:48.834+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:34:48.834+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:48.841+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:34:48.839+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:34:48.841+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:34:48.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T08:35:19.832+0000] {processor.py:161} INFO - Started process (PID=5239) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:35:19.834+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:35:19.838+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:35:19.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:35:19.846+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:35:19.845+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:35:19.847+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:35:19.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.053 seconds
[2025-03-23T08:35:58.481+0000] {processor.py:161} INFO - Started process (PID=5243) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:35:58.482+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:35:58.484+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:35:58.484+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:35:58.490+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:35:58.489+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:35:58.491+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:35:58.520+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:36:58.584+0000] {processor.py:161} INFO - Started process (PID=5348) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:36:58.586+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:36:58.590+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:36:58.589+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:36:58.595+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:36:58.594+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:36:58.596+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:36:58.622+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:37:33.856+0000] {processor.py:161} INFO - Started process (PID=5451) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:37:33.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:37:33.860+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:37:33.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:37:33.868+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:37:33.867+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:36:56.514+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:36:56.547+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:37:54.428+0000] {processor.py:161} INFO - Started process (PID=5507) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:37:54.429+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:37:54.431+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:37:54.431+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:37:54.441+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:37:54.439+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:37:54.442+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:37:54.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:38:24.994+0000] {processor.py:161} INFO - Started process (PID=5569) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:38:24.997+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:38:25.000+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:38:25.000+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:38:25.011+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:38:25.008+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:38:25.011+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:38:25.044+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.054 seconds
[2025-03-23T08:39:03.947+0000] {processor.py:161} INFO - Started process (PID=5593) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:39:03.948+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:39:03.951+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:39:03.950+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:39:03.957+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:39:03.955+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:39:03.957+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:39:03.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T08:38:57.099+0000] {processor.py:161} INFO - Started process (PID=5644) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:38:57.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:38:57.103+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:38:57.102+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:38:57.111+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:38:57.109+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:38:57.112+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:38:57.141+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:39:27.203+0000] {processor.py:161} INFO - Started process (PID=5696) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:39:27.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:39:27.206+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:39:27.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:39:27.212+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:39:27.210+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:39:27.212+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:39:27.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:40:08.939+0000] {processor.py:161} INFO - Started process (PID=5739) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:40:08.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:40:08.944+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:40:08.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:40:08.950+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:40:08.948+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:40:08.951+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:40:08.979+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:40:39.193+0000] {processor.py:161} INFO - Started process (PID=5909) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:40:39.195+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:40:39.199+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:40:39.198+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:40:39.209+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:40:39.206+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:40:39.210+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:40:39.248+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.061 seconds
[2025-03-23T08:41:24.071+0000] {processor.py:161} INFO - Started process (PID=5939) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:41:24.072+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:41:24.077+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:41:24.077+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:41:24.086+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:41:24.084+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:41:24.086+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:41:24.122+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.058 seconds
[2025-03-23T08:41:59.292+0000] {processor.py:161} INFO - Started process (PID=6037) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:41:59.293+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:41:59.297+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:41:59.296+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:41:59.304+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:41:59.302+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:41:59.305+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:41:59.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:42:39.426+0000] {processor.py:161} INFO - Started process (PID=6177) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:42:39.428+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:42:39.432+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:42:39.432+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:42:39.440+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:42:39.439+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:42:39.441+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:42:02.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.055 seconds
[2025-03-23T08:42:32.501+0000] {processor.py:161} INFO - Started process (PID=6233) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:42:32.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:42:32.506+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:42:32.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:42:32.515+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:42:32.513+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:42:32.515+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:42:32.543+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T08:43:14.566+0000] {processor.py:161} INFO - Started process (PID=6284) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:43:14.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:43:14.574+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:43:14.573+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:43:14.588+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:43:14.585+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:43:14.589+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:43:14.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.068 seconds
[2025-03-23T08:44:04.270+0000] {processor.py:161} INFO - Started process (PID=6381) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:44:04.272+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:44:04.275+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:44:04.275+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:44:04.284+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:44:04.282+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:44:04.284+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:44:04.313+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T08:44:34.645+0000] {processor.py:161} INFO - Started process (PID=6533) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:44:34.647+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:44:34.651+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:44:34.650+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:44:34.657+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:44:34.656+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:44:34.657+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:44:34.686+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T08:45:25.311+0000] {processor.py:161} INFO - Started process (PID=6544) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:45:25.313+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:45:25.316+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:45:25.315+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:45:25.323+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:45:25.322+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:45:25.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:45:25.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T08:45:59.937+0000] {processor.py:161} INFO - Started process (PID=6600) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:45:59.939+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:45:59.944+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:45:59.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:45:59.953+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:45:59.951+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:45:59.954+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:45:59.984+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.052 seconds
[2025-03-23T08:46:25.178+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:46:25.180+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:46:25.183+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:46:25.182+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:46:25.190+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:46:25.188+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:46:25.190+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:46:25.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.050 seconds
[2025-03-23T08:47:09.784+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:47:09.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:47:09.787+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:47:09.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:47:09.793+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:47:09.791+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:47:09.793+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:47:09.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T08:47:39.915+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:47:39.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:47:39.919+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:47:39.919+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:47:39.927+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:47:39.925+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:47:39.928+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:47:39.964+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.057 seconds
[2025-03-23T08:48:44.852+0000] {processor.py:161} INFO - Started process (PID=302) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:48:44.853+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:48:44.856+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:48:44.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:48:44.862+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:48:44.861+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:48:44.862+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:48:44.889+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:49:15.536+0000] {processor.py:161} INFO - Started process (PID=491) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:15.539+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:49:15.544+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:49:15.543+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:15.553+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:49:15.551+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:49:15.554+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:15.589+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.058 seconds
[2025-03-23T08:49:17.848+0000] {processor.py:161} INFO - Started process (PID=496) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:17.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:49:17.853+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:49:17.853+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:17.862+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:49:17.860+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:49:17.863+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:17.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.054 seconds
[2025-03-23T08:49:48.473+0000] {processor.py:161} INFO - Started process (PID=552) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:48.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:49:48.477+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:49:48.477+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:48.484+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:49:48.483+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:49:48.484+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:49:48.512+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:50:30.206+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:50:30.207+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:50:30.211+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:50:30.210+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:50:30.218+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:50:30.217+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:50:30.219+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:50:30.261+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.060 seconds
[2025-03-23T08:51:00.383+0000] {processor.py:161} INFO - Started process (PID=768) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:00.386+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:51:00.388+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:51:00.388+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:00.400+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:51:00.397+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:51:00.400+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:00.423+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T08:51:31.180+0000] {processor.py:161} INFO - Started process (PID=820) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:31.182+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:51:31.185+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:51:31.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:31.191+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:51:31.189+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:51:31.192+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:31.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:51:58.212+0000] {processor.py:161} INFO - Started process (PID=848) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:58.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:51:58.219+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:51:58.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:58.228+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:51:58.226+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:51:58.229+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:51:58.264+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.057 seconds
[2025-03-23T08:52:28.396+0000] {processor.py:161} INFO - Started process (PID=897) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:28.398+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:28.401+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:28.401+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:28.406+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:28.405+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:52:28.407+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:28.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:10.261+0000] {processor.py:161} INFO - Started process (PID=947) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:10.264+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:10.267+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:10.266+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:10.272+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:10.271+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 23, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 420, in apply_defaults
    raise AirflowException(f"missing keyword argument {missing_args.pop()!r}")
airflow.exceptions.AirflowException: missing keyword argument 'bucket'
[2025-03-23T08:53:10.273+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:10.301+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:52:58.707+0000] {processor.py:161} INFO - Started process (PID=997) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.708+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:58.711+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.710+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.720+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.717+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:58.720+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.742+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.038 seconds
[2025-03-23T08:52:58.764+0000] {processor.py:161} INFO - Started process (PID=998) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.765+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:58.767+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.767+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.773+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.772+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:58.773+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.795+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.035 seconds
[2025-03-23T08:52:58.817+0000] {processor.py:161} INFO - Started process (PID=999) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.818+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:58.821+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.820+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.828+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.826+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:58.828+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.037 seconds
[2025-03-23T08:52:58.871+0000] {processor.py:161} INFO - Started process (PID=1000) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:58.874+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.879+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.878+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:58.880+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.033 seconds
[2025-03-23T08:52:58.923+0000] {processor.py:161} INFO - Started process (PID=1001) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:58.926+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.931+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.930+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:58.931+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.955+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.036 seconds
[2025-03-23T08:52:58.985+0000] {processor.py:161} INFO - Started process (PID=1002) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:58.990+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:58.997+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:58.996+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:58.998+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:52:59.055+0000] {processor.py:161} INFO - Started process (PID=1003) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.059+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.058+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.069+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.067+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.069+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.099+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:52:59.128+0000] {processor.py:161} INFO - Started process (PID=1004) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.132+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.131+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.137+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.136+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.139+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.170+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:52:59.193+0000] {processor.py:161} INFO - Started process (PID=1005) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.194+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.196+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.196+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.203+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.202+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.203+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.037 seconds
[2025-03-23T08:52:59.252+0000] {processor.py:161} INFO - Started process (PID=1006) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.254+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.256+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.256+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.261+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.260+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.262+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.047 seconds
[2025-03-23T08:52:59.324+0000] {processor.py:161} INFO - Started process (PID=1007) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.325+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.329+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.339+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.337+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.340+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.053 seconds
[2025-03-23T08:52:59.401+0000] {processor.py:161} INFO - Started process (PID=1008) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.403+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.404+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.404+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.412+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.411+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.442+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:52:59.470+0000] {processor.py:161} INFO - Started process (PID=1009) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.473+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.473+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.480+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.478+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.480+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.506+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:52:59.528+0000] {processor.py:161} INFO - Started process (PID=1010) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.529+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.532+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.531+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.538+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.537+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.539+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T08:52:59.590+0000] {processor.py:161} INFO - Started process (PID=1011) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.593+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.593+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.601+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.600+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.601+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.627+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T08:52:59.649+0000] {processor.py:161} INFO - Started process (PID=1012) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.653+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.653+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.661+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.660+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.662+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.691+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:52:59.721+0000] {processor.py:161} INFO - Started process (PID=1013) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.722+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.724+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.723+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.729+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.728+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.730+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.759+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:52:59.794+0000] {processor.py:161} INFO - Started process (PID=1015) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.795+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.799+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.799+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.806+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.805+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.807+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.840+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.050 seconds
[2025-03-23T08:52:59.867+0000] {processor.py:161} INFO - Started process (PID=1021) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.873+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.882+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.880+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.882+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.914+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:52:59.948+0000] {processor.py:161} INFO - Started process (PID=1022) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:52:59.956+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.955+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:52:59.969+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:52:59.964+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:52:59.971+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.009+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.067 seconds
[2025-03-23T08:53:00.049+0000] {processor.py:161} INFO - Started process (PID=1023) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.050+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.056+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.055+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.072+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.069+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.073+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.164+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.122 seconds
[2025-03-23T08:53:00.201+0000] {processor.py:161} INFO - Started process (PID=1024) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.202+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.206+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.205+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.214+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.212+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.215+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.245+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.050 seconds
[2025-03-23T08:53:00.277+0000] {processor.py:161} INFO - Started process (PID=1025) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.279+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.282+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.282+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.292+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.290+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.293+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.317+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:53:00.339+0000] {processor.py:161} INFO - Started process (PID=1026) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.340+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.342+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.342+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.349+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.348+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.350+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.375+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T08:53:00.401+0000] {processor.py:161} INFO - Started process (PID=1027) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.405+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.405+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.411+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.410+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.412+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.441+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:53:00.470+0000] {processor.py:161} INFO - Started process (PID=1028) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.471+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.475+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.474+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.481+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.480+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.481+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.508+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:53:00.535+0000] {processor.py:161} INFO - Started process (PID=1029) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.538+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.538+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.545+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.544+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.546+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:00.608+0000] {processor.py:161} INFO - Started process (PID=1030) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.614+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.624+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.622+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.625+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.656+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.055 seconds
[2025-03-23T08:53:00.688+0000] {processor.py:161} INFO - Started process (PID=1031) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.689+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.695+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.694+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.705+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.702+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.706+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.054 seconds
[2025-03-23T08:53:00.770+0000] {processor.py:161} INFO - Started process (PID=1032) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.771+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.775+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.774+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.783+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.780+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.784+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.811+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T08:53:00.836+0000] {processor.py:161} INFO - Started process (PID=1033) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.837+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.840+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.839+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.847+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.845+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.847+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.877+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:53:00.907+0000] {processor.py:161} INFO - Started process (PID=1034) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.909+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.911+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.911+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.917+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.916+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.918+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.947+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:53:00.975+0000] {processor.py:161} INFO - Started process (PID=1035) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:00.977+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.977+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:00.983+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:00.982+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:00.984+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.011+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:53:01.036+0000] {processor.py:161} INFO - Started process (PID=1036) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.041+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.049+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.047+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.050+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.083+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.052 seconds
[2025-03-23T08:53:01.114+0000] {processor.py:161} INFO - Started process (PID=1037) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.115+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.119+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.118+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.129+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.126+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.130+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:53:01.180+0000] {processor.py:161} INFO - Started process (PID=1038) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.184+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.192+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.189+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.192+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.221+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:53:01.243+0000] {processor.py:161} INFO - Started process (PID=1039) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.248+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.248+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.255+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.254+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.256+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.284+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:53:01.325+0000] {processor.py:161} INFO - Started process (PID=1040) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.333+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.332+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.339+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.337+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.339+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T08:53:01.386+0000] {processor.py:161} INFO - Started process (PID=1041) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.388+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.392+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.391+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.399+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.397+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.399+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.426+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:01.453+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.455+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.457+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.457+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.465+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.463+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.465+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:01.518+0000] {processor.py:161} INFO - Started process (PID=1043) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.520+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.523+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.530+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.529+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.531+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:53:01.577+0000] {processor.py:161} INFO - Started process (PID=1044) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.578+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.582+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.581+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.588+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.586+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.588+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.612+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.038 seconds
[2025-03-23T08:53:01.640+0000] {processor.py:161} INFO - Started process (PID=1045) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.644+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.644+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.650+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.648+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.650+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:53:01.700+0000] {processor.py:161} INFO - Started process (PID=1046) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.703+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.703+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.710+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.709+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.710+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T08:53:01.773+0000] {processor.py:161} INFO - Started process (PID=1047) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.779+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.787+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.785+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.787+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:53:01.843+0000] {processor.py:161} INFO - Started process (PID=1048) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.846+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.851+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.850+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.864+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.859+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.865+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.897+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.057 seconds
[2025-03-23T08:53:01.931+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:01.935+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.935+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.945+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:01.944+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:01.946+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:01.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.060 seconds
[2025-03-23T08:53:02.016+0000] {processor.py:161} INFO - Started process (PID=1050) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.017+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.022+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.021+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.032+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.029+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.033+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.056 seconds
[2025-03-23T08:53:02.103+0000] {processor.py:161} INFO - Started process (PID=1051) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.104+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.108+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.107+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.118+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.115+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.119+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.060 seconds
[2025-03-23T08:53:02.189+0000] {processor.py:161} INFO - Started process (PID=1052) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.192+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.194+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.194+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.200+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.199+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.201+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.236+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.053 seconds
[2025-03-23T08:53:02.265+0000] {processor.py:161} INFO - Started process (PID=1053) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.266+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.271+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.271+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.278+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.276+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.278+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.306+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T08:53:02.332+0000] {processor.py:161} INFO - Started process (PID=1054) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.333+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.336+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.336+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.343+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.341+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.343+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:53:02.398+0000] {processor.py:161} INFO - Started process (PID=1055) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.399+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.401+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.401+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.408+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.406+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.408+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.435+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T08:53:02.461+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.464+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.471+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.470+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.471+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.492+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.035 seconds
[2025-03-23T08:53:02.512+0000] {processor.py:161} INFO - Started process (PID=1057) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.516+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.515+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.525+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.524+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.525+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.553+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:53:02.581+0000] {processor.py:161} INFO - Started process (PID=1058) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.582+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.585+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.585+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.591+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.590+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.591+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T08:53:02.644+0000] {processor.py:161} INFO - Started process (PID=1059) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.645+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.647+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.647+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.653+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.652+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.654+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:02.716+0000] {processor.py:161} INFO - Started process (PID=1060) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.717+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.721+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.721+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.726+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.725+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.727+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.751+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.041 seconds
[2025-03-23T08:53:02.777+0000] {processor.py:161} INFO - Started process (PID=1061) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.778+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.780+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.786+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.785+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.786+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.812+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:53:02.835+0000] {processor.py:161} INFO - Started process (PID=1062) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.837+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.837+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.844+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.842+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.844+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.867+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.036 seconds
[2025-03-23T08:53:02.888+0000] {processor.py:161} INFO - Started process (PID=1063) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.889+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:02.892+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.892+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:02.900+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:02.898+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:02.900+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:40.228+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.040 seconds
[2025-03-23T08:53:26.708+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:26.711+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:26.714+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:26.714+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:26.722+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:26.720+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:26.723+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:26.753+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:53:30.903+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:30.904+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:30.909+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:30.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:30.923+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:30.919+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:30.924+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:30.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.075 seconds
[2025-03-23T08:53:30.992+0000] {processor.py:161} INFO - Started process (PID=108) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:30.993+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:30.996+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:30.996+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.003+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.002+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.004+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.039+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.052 seconds
[2025-03-23T08:53:31.072+0000] {processor.py:161} INFO - Started process (PID=109) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.076+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.084+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.083+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.085+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.118+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.051 seconds
[2025-03-23T08:53:31.149+0000] {processor.py:161} INFO - Started process (PID=110) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.152+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.151+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.157+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.156+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.158+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.187+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:53:31.222+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.223+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.226+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.234+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.232+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.235+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.262+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.045 seconds
[2025-03-23T08:53:31.285+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.289+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.295+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.293+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.295+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.321+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:53:31.346+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.347+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.352+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.358+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.357+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.358+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.388+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.046 seconds
[2025-03-23T08:53:31.410+0000] {processor.py:161} INFO - Started process (PID=114) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.413+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.413+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.418+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.417+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.419+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.439+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.034 seconds
[2025-03-23T08:53:31.459+0000] {processor.py:161} INFO - Started process (PID=115) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.462+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.462+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.467+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.466+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.467+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.488+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.033 seconds
[2025-03-23T08:53:31.508+0000] {processor.py:161} INFO - Started process (PID=116) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.512+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.517+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.515+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.517+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.538+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.034 seconds
[2025-03-23T08:53:31.559+0000] {processor.py:161} INFO - Started process (PID=117) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.564+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.571+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.570+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.572+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:31.628+0000] {processor.py:161} INFO - Started process (PID=118) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.630+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.634+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.633+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.640+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.639+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.640+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.672+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.048 seconds
[2025-03-23T08:53:31.703+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.704+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.706+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.705+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.715+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.714+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.716+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.750+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.053 seconds
[2025-03-23T08:53:31.778+0000] {processor.py:161} INFO - Started process (PID=120) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.779+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.782+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.782+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.789+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.788+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.790+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.816+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:31.843+0000] {processor.py:161} INFO - Started process (PID=121) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.846+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.846+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.854+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.853+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.855+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.887+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T08:53:31.909+0000] {processor.py:161} INFO - Started process (PID=122) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.911+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.913+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.913+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.920+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.918+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.920+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.941+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.035 seconds
[2025-03-23T08:53:31.963+0000] {processor.py:161} INFO - Started process (PID=123) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.964+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:31.966+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.966+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.971+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:31.970+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:31.972+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:31.994+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.035 seconds
[2025-03-23T08:53:32.017+0000] {processor.py:161} INFO - Started process (PID=124) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.020+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.019+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.026+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.025+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.027+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.048+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.034 seconds
[2025-03-23T08:53:32.069+0000] {processor.py:161} INFO - Started process (PID=125) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.072+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.078+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.076+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.078+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.101+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.036 seconds
[2025-03-23T08:53:32.125+0000] {processor.py:161} INFO - Started process (PID=126) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.128+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.128+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.134+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.133+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.134+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.157+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.035 seconds
[2025-03-23T08:53:32.180+0000] {processor.py:161} INFO - Started process (PID=127) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.181+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.184+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.184+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.192+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.190+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.193+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.224+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.049 seconds
[2025-03-23T08:53:32.247+0000] {processor.py:161} INFO - Started process (PID=128) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.248+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.250+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.250+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.259+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.257+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.259+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.285+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:32.313+0000] {processor.py:161} INFO - Started process (PID=129) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.314+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.317+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.316+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.324+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.322+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.324+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.352+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:53:32.377+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.381+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.381+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.388+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.386+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.389+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.416+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.044 seconds
[2025-03-23T08:53:32.439+0000] {processor.py:161} INFO - Started process (PID=131) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.444+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.443+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.449+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.447+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.449+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.039 seconds
[2025-03-23T08:53:32.502+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.504+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.507+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.507+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.515+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.513+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.515+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.541+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.043 seconds
[2025-03-23T08:53:32.567+0000] {processor.py:161} INFO - Started process (PID=133) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.568+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.570+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.570+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.575+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.574+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.576+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.599+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.036 seconds
[2025-03-23T08:53:32.621+0000] {processor.py:161} INFO - Started process (PID=134) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.624+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.624+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.630+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.629+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.631+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.035 seconds
[2025-03-23T08:53:32.674+0000] {processor.py:161} INFO - Started process (PID=135) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.677+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.677+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.682+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.681+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.683+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.035 seconds
[2025-03-23T08:53:32.729+0000] {processor.py:161} INFO - Started process (PID=136) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.730+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.732+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.737+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.736+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.738+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.762+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.037 seconds
[2025-03-23T08:53:32.785+0000] {processor.py:161} INFO - Started process (PID=137) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.786+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.789+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.788+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.796+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.794+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.796+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.819+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.038 seconds
[2025-03-23T08:53:32.843+0000] {processor.py:161} INFO - Started process (PID=138) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.844+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.845+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.845+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.854+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.851+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.856+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.882+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.042 seconds
[2025-03-23T08:53:32.904+0000] {processor.py:161} INFO - Started process (PID=139) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:53:32.907+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.907+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:53:32.917+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:53:32.914+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:53:32.918+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:54:10.280+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.052 seconds
[2025-03-23T08:54:40.892+0000] {processor.py:161} INFO - Started process (PID=204) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:54:40.894+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:54:40.898+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:54:40.897+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:54:40.907+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:54:40.905+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/load_csv_to_bq.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/load_csv_to_bq.py", line 35, in <module>
    load_csv_to_bq = GCSToBigQueryOperator(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/providers/google/cloud/transfers/gcs_to_bigquery.py", line 234, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 437, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/baseoperator.py", line 793, in __init__
    raise AirflowException(
airflow.exceptions.AirflowException: Invalid arguments were passed to GCSToBigQueryOperator (task_id: load_csv_to_bq). Invalid arguments were:
**kwargs: {'google_cloud_storage_conn_id': 'google_cloud_default', 'bigquery_conn_id': 'google_cloud_default'}
[2025-03-23T08:54:40.907+0000] {processor.py:842} WARNING - No viable dags retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:54:40.943+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.057 seconds
[2025-03-23T08:55:00.821+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:55:00.823+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:55:00.827+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:00.827+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:55:00.861+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:55:00.996+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:00.995+0000] {override.py:1769} INFO - Created Permission View: can delete on DAG:load_csv_to_bq
[2025-03-23T08:55:01.013+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:01.012+0000] {override.py:1769} INFO - Created Permission View: can edit on DAG:load_csv_to_bq
[2025-03-23T08:55:01.025+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:01.024+0000] {override.py:1769} INFO - Created Permission View: can read on DAG:load_csv_to_bq
[2025-03-23T08:55:01.026+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:01.025+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T08:55:01.038+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:01.038+0000] {dag.py:3069} INFO - Creating ORM DAG for load_csv_to_bq
[2025-03-23T08:55:01.039+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:01.039+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T08:55:01.065+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.252 seconds
[2025-03-23T08:55:55.476+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:55:55.478+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:55:55.481+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:55.481+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:55:55.495+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:55:55.523+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:55.522+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T08:55:55.542+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:55:55.542+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T08:55:55.576+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T08:56:35.546+0000] {processor.py:161} INFO - Started process (PID=214) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:56:35.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:56:35.552+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:56:35.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:56:35.565+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:56:35.600+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:56:35.599+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T08:56:35.619+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:56:35.619+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T08:56:35.657+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.116 seconds
[2025-03-23T08:57:20.679+0000] {processor.py:161} INFO - Started process (PID=317) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:57:20.682+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:57:20.685+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:57:20.685+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:57:20.701+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:57:20.735+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:57:20.735+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T08:57:20.749+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:57:20.749+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T08:57:20.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.113 seconds
[2025-03-23T08:57:50.815+0000] {processor.py:161} INFO - Started process (PID=418) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:57:50.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:57:50.819+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:57:50.819+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:57:50.829+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:57:50.855+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:57:50.855+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T08:57:50.868+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:57:50.868+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T08:57:50.892+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.081 seconds
[2025-03-23T08:58:50.969+0000] {processor.py:161} INFO - Started process (PID=466) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:58:50.971+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:58:50.975+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:58:50.974+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:58:50.989+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:58:51.017+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:58:51.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T08:58:51.038+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:58:51.037+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T08:58:51.068+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T08:59:30.870+0000] {processor.py:161} INFO - Started process (PID=611) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:59:30.872+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T08:59:30.875+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:59:30.875+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:59:30.884+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T08:59:30.915+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:59:30.915+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T08:59:30.934+0000] {logging_mixin.py:188} INFO - [2025-03-23T08:59:30.934+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T08:59:30.965+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T09:00:36.031+0000] {processor.py:161} INFO - Started process (PID=763) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:00:36.033+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:00:36.035+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:00:36.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:00:36.044+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:00:36.071+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:00:36.071+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:00:36.086+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:00:36.086+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:00:36.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T09:01:41.097+0000] {processor.py:161} INFO - Started process (PID=915) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:01:41.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:01:41.102+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:01:41.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:01:41.115+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:01:41.145+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:01:41.144+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:01:41.163+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:01:41.162+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:01:41.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T09:02:06.869+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:02:06.871+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:02:06.874+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:02:06.874+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:02:06.892+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:02:06.924+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:02:06.924+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:02:06.943+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:02:06.943+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:02:06.976+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.114 seconds
[2025-03-23T09:02:37.465+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:02:37.466+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:02:37.470+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:02:37.470+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:02:37.485+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:02:37.519+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:02:37.519+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:02:37.535+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:02:37.535+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:02:37.566+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T09:03:21.924+0000] {processor.py:161} INFO - Started process (PID=159) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:03:21.926+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:03:21.929+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:03:21.928+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:03:21.942+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:03:21.976+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:03:21.975+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:03:21.995+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:03:21.995+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:03:22.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T09:03:52.220+0000] {processor.py:161} INFO - Started process (PID=215) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:03:52.222+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:03:52.225+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:03:52.225+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:03:52.234+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:03:52.254+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:03:52.254+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:03:52.270+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:03:52.270+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:03:52.295+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.080 seconds
[2025-03-23T09:04:36.279+0000] {processor.py:161} INFO - Started process (PID=271) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:04:36.280+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:04:36.284+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:04:36.284+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:04:36.294+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:04:36.322+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:04:36.321+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:04:36.337+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:04:36.337+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:04:36.370+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T09:05:11.595+0000] {processor.py:161} INFO - Started process (PID=374) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:05:11.596+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:05:11.598+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:05:11.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:05:11.610+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:04:34.326+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:04:34.326+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:04:34.346+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:04:34.346+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:04:34.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T09:05:16.429+0000] {processor.py:161} INFO - Started process (PID=424) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:05:16.431+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:05:16.434+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:05:16.433+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:05:16.445+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:05:16.469+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:05:16.469+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:05:16.483+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:05:16.483+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:05:16.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.084 seconds
[2025-03-23T09:05:14.421+0000] {processor.py:161} INFO - Started process (PID=534) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:05:14.424+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:05:14.427+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:05:14.427+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:05:14.444+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:05:14.482+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:05:14.481+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:05:14.511+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:05:14.511+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:05:14.551+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.136 seconds
[2025-03-23T09:06:11.460+0000] {processor.py:161} INFO - Started process (PID=584) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:06:11.462+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:06:11.464+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:06:11.464+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:06:11.474+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:06:11.507+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:06:11.507+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:06:11.525+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:06:11.525+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:06:11.556+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T09:07:01.573+0000] {processor.py:161} INFO - Started process (PID=692) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:07:01.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:07:01.577+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:07:01.577+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:07:01.586+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:07:01.610+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:07:01.609+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:07:01.625+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:07:01.625+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:07:01.649+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.079 seconds
[2025-03-23T09:07:36.765+0000] {processor.py:161} INFO - Started process (PID=794) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:07:36.769+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:07:36.774+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:07:36.773+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:07:36.790+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:07:36.816+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:07:36.815+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:07:36.833+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:07:36.833+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:07:36.860+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T09:08:11.927+0000] {processor.py:161} INFO - Started process (PID=898) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:08:11.929+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:08:11.931+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:08:11.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:08:11.941+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:08:11.962+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:08:11.961+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:08:11.977+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:08:11.976+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:08:11.997+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.074 seconds
[2025-03-23T09:08:42.156+0000] {processor.py:161} INFO - Started process (PID=1056) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:08:42.158+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:08:42.160+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:08:42.160+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:08:42.169+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:08:42.191+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:08:42.190+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:08:42.203+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:08:42.203+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:08:42.225+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.073 seconds
[2025-03-23T09:09:46.931+0000] {processor.py:161} INFO - Started process (PID=1095) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:09:46.932+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:09:46.938+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:09:46.937+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:09:46.952+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:09:46.980+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:09:46.980+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:09:47.001+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:09:47.000+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:09:47.032+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T09:10:27.132+0000] {processor.py:161} INFO - Started process (PID=1240) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:10:27.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:10:27.135+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:10:27.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:10:27.148+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:10:27.173+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:10:27.173+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:10:27.188+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:10:27.187+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:10:27.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T09:11:32.256+0000] {processor.py:161} INFO - Started process (PID=1396) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:11:32.259+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:11:32.261+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:11:32.261+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:11:32.276+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:11:32.307+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:11:32.307+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:11:32.322+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:11:32.322+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:11:32.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T09:11:18.058+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:11:18.060+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:11:18.063+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:11:18.063+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:11:18.082+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:11:18.111+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:11:18.111+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:11:18.124+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:11:18.124+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:11:18.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T09:12:02.700+0000] {processor.py:161} INFO - Started process (PID=101) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:12:02.701+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:12:02.704+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:12:02.703+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:12:02.715+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:12:02.740+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:12:02.739+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:12:02.755+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:12:02.754+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:12:02.778+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.083 seconds
[2025-03-23T09:12:42.825+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:12:42.827+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:12:42.829+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:12:42.829+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:12:42.840+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:12:42.867+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:12:42.867+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:12:42.882+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:12:42.882+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:12:42.913+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T09:13:17.504+0000] {processor.py:161} INFO - Started process (PID=209) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:13:17.507+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:13:17.511+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:13:17.511+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:13:17.527+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:12:40.254+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:12:40.253+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:12:40.275+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:12:40.275+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:12:40.311+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.122 seconds
[2025-03-23T09:13:22.295+0000] {processor.py:161} INFO - Started process (PID=259) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:13:22.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:13:22.299+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:13:22.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:13:22.311+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:13:22.338+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:13:22.337+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:13:22.357+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:13:22.357+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:13:22.391+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T09:13:57.382+0000] {processor.py:161} INFO - Started process (PID=367) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:13:57.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:13:57.387+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:13:57.387+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:13:57.399+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:13:57.430+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:13:57.429+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:13:57.449+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:13:57.449+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:13:57.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T09:14:27.735+0000] {processor.py:161} INFO - Started process (PID=521) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:14:27.738+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:14:27.741+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:14:27.740+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:14:27.754+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:14:27.782+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:14:27.781+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:14:27.798+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:14:27.797+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:14:27.829+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T09:15:32.594+0000] {processor.py:161} INFO - Started process (PID=566) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:15:32.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:15:32.597+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:15:32.597+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:15:32.607+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:15:32.636+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:15:32.636+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:15:32.652+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:15:32.651+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:15:32.677+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T09:16:03.360+0000] {processor.py:161} INFO - Started process (PID=725) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:16:03.362+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:16:03.365+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:16:03.364+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:16:03.377+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:16:03.412+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:16:03.411+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:16:03.433+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:16:03.432+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:16:03.468+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.112 seconds
[2025-03-23T09:16:33.682+0000] {processor.py:161} INFO - Started process (PID=777) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:16:33.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:16:33.686+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:16:33.686+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:16:33.698+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:16:33.728+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:16:33.727+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:16:33.744+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:16:33.744+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:16:33.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T09:17:12.738+0000] {processor.py:161} INFO - Started process (PID=797) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:17:12.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:17:12.743+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:17:12.742+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:17:12.754+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:17:12.781+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:17:12.781+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:17:12.799+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:17:12.799+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:17:12.826+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T09:18:08.020+0000] {processor.py:161} INFO - Started process (PID=974) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:18:08.022+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:18:08.025+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:18:08.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:18:08.036+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:18:08.061+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:18:08.060+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:18:08.076+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:18:08.076+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:18:08.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T09:18:38.560+0000] {processor.py:161} INFO - Started process (PID=1036) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:18:38.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:18:38.565+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:18:38.565+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:18:38.581+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:18:38.613+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:18:38.613+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:18:38.629+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:18:38.629+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:18:38.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.107 seconds
[2025-03-23T09:19:43.117+0000] {processor.py:161} INFO - Started process (PID=51) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:19:43.119+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:19:43.122+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:19:43.121+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:19:43.141+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:19:43.170+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:19:43.170+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:19:43.185+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:19:43.184+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:19:43.212+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T09:20:18.125+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:20:18.127+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:20:18.129+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:20:18.128+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:20:18.145+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:20:18.180+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:20:18.180+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:20:18.201+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:20:18.200+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:20:18.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.113 seconds
[2025-03-23T09:20:48.561+0000] {processor.py:161} INFO - Started process (PID=258) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:20:48.564+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:20:48.568+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:20:48.567+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:20:48.577+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:20:48.605+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:20:48.604+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:20:48.618+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:20:48.618+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:20:48.646+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T09:21:33.212+0000] {processor.py:161} INFO - Started process (PID=289) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:21:33.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:21:33.216+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:21:33.216+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:21:33.226+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:21:33.256+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:21:33.255+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:21:33.271+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:21:33.271+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:21:33.298+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T09:21:31.215+0000] {processor.py:161} INFO - Started process (PID=388) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:21:31.220+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:21:31.223+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:21:31.222+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:21:31.237+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:21:31.266+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:21:31.265+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:21:31.279+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:21:31.279+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:21:31.314+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T09:22:01.696+0000] {processor.py:161} INFO - Started process (PID=444) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:01.697+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:22:01.700+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:01.700+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:01.713+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:01.736+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:01.735+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:22:01.753+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:01.752+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:22:01.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T09:22:15.655+0000] {processor.py:161} INFO - Started process (PID=500) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:15.656+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:22:15.659+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:15.659+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:15.668+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:15.689+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:15.688+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:22:15.700+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:15.700+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:22:15.724+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.075 seconds
[2025-03-23T09:22:45.891+0000] {processor.py:161} INFO - Started process (PID=556) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:45.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:22:45.896+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:45.896+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:45.911+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:22:45.942+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:45.942+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:22:45.968+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:22:45.967+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:22:46.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.120 seconds
[2025-03-23T09:23:29.082+0000] {processor.py:161} INFO - Started process (PID=45) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:23:29.084+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:23:29.087+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:23:29.087+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:23:29.106+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:23:29.143+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:23:29.142+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:23:29.166+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:23:29.166+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:23:29.201+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.127 seconds
[2025-03-23T09:24:18.416+0000] {processor.py:161} INFO - Started process (PID=101) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:24:18.417+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:24:18.420+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:24:18.419+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:24:18.430+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:24:18.458+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:24:18.458+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:24:18.474+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:24:18.473+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:24:18.504+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T09:24:53.482+0000] {processor.py:161} INFO - Started process (PID=195) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:24:53.484+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:24:53.487+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:24:53.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:24:53.498+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:24:53.523+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:24:53.522+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:24:53.539+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:24:53.539+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:24:53.568+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T09:25:24.036+0000] {processor.py:161} INFO - Started process (PID=348) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:25:24.037+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:25:24.039+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:25:24.039+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:25:24.051+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:25:24.080+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:25:24.080+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:25:24.097+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:25:24.096+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:25:24.132+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T09:26:14.617+0000] {processor.py:161} INFO - Started process (PID=358) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:26:14.618+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:26:14.620+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:26:14.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:26:14.631+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:26:14.657+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:26:14.657+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:26:14.674+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:26:14.674+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:26:14.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T09:26:45.403+0000] {processor.py:161} INFO - Started process (PID=420) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:26:45.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:26:45.407+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:26:45.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:26:45.417+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:26:45.439+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:26:45.439+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:26:45.452+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:26:45.451+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:26:45.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.078 seconds
[2025-03-23T09:27:28.879+0000] {processor.py:161} INFO - Started process (PID=467) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:27:28.880+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:27:28.882+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:27:28.882+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:27:28.896+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:27:28.927+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:27:28.926+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:27:28.940+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:27:28.940+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:27:28.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T09:27:59.939+0000] {processor.py:161} INFO - Started process (PID=649) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:27:59.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:27:59.943+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:27:59.943+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:27:59.953+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:27:59.984+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:27:59.984+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:27:59.998+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:27:59.998+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:28:00.029+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T09:28:30.746+0000] {processor.py:161} INFO - Started process (PID=719) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:28:30.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:28:30.751+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:28:30.751+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:28:30.764+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:28:30.800+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:28:30.799+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:28:30.819+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:28:30.819+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:28:30.851+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.111 seconds
[2025-03-23T09:29:09.127+0000] {processor.py:161} INFO - Started process (PID=721) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:29:09.129+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:29:09.132+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:29:09.132+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:29:09.145+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:29:09.175+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:29:09.174+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:29:09.187+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:29:09.187+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:29:09.218+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T09:29:39.628+0000] {processor.py:161} INFO - Started process (PID=828) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:29:39.631+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:29:39.634+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:29:39.633+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:29:39.645+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:29:39.671+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:29:39.670+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:29:39.687+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:29:39.686+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:29:39.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T09:30:20.046+0000] {processor.py:161} INFO - Started process (PID=830) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:30:20.047+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:30:20.052+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:30:20.051+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:30:20.063+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:30:20.089+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:30:20.088+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:30:20.102+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:30:20.102+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:30:20.131+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T09:30:50.990+0000] {processor.py:161} INFO - Started process (PID=886) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:30:50.995+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:30:50.998+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:30:50.997+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:30:51.007+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:30:51.033+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:30:51.032+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:30:51.045+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:30:51.045+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:30:51.067+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.081 seconds
[2025-03-23T09:31:29.248+0000] {processor.py:161} INFO - Started process (PID=942) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:31:29.250+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:31:29.252+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:31:29.252+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:31:29.262+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:31:29.284+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:31:29.284+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:31:29.298+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:31:29.298+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:31:29.324+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.080 seconds
[2025-03-23T09:32:24.346+0000] {processor.py:161} INFO - Started process (PID=1049) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:24.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:32:24.352+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:24.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:24.368+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:24.402+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:24.400+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:32:24.424+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:24.424+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:32:24.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.118 seconds
[2025-03-23T09:32:59.438+0000] {processor.py:161} INFO - Started process (PID=1153) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:59.440+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:32:59.442+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:59.442+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:59.454+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:59.483+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:59.482+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:32:59.497+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:59.497+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:32:59.527+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T09:32:52.548+0000] {processor.py:161} INFO - Started process (PID=1209) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:52.550+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:32:52.554+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:52.553+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:52.564+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:32:52.595+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:52.595+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:32:52.608+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:32:52.607+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:32:52.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T09:33:22.939+0000] {processor.py:161} INFO - Started process (PID=1261) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:33:22.941+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:33:22.946+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:33:22.946+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:33:22.959+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:33:22.989+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:33:22.988+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:33:23.005+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:33:23.004+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:33:23.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T09:34:04.705+0000] {processor.py:161} INFO - Started process (PID=1307) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:34:04.706+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:34:04.709+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:34:04.708+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:34:04.719+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:34:04.746+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:34:04.745+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:34:04.761+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:34:04.760+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:34:04.790+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T09:34:44.610+0000] {processor.py:161} INFO - Started process (PID=1463) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:34:44.613+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:34:44.616+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:34:44.615+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:34:44.642+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:34:44.686+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:34:44.685+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:34:44.706+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:34:44.706+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:34:44.736+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.138 seconds
[2025-03-23T09:35:15.170+0000] {processor.py:161} INFO - Started process (PID=1564) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:15.171+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:35:15.174+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:15.173+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:15.184+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:15.204+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:15.204+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:34:38.101+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:34:38.101+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:34:38.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.085 seconds
[2025-03-23T09:35:29.657+0000] {processor.py:161} INFO - Started process (PID=1612) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:29.659+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:35:29.662+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:29.661+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:29.673+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:29.700+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:29.699+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:35:29.718+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:29.718+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:35:29.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T09:36:04.950+0000] {processor.py:161} INFO - Started process (PID=1714) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:04.952+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:36:04.955+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:36:04.954+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:04.968+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:04.994+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:36:04.994+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:35:27.741+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:27.741+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:35:27.776+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T09:35:58.382+0000] {processor.py:161} INFO - Started process (PID=1770) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:58.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:35:58.386+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:58.386+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:58.396+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:35:58.423+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:58.422+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:35:58.436+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:35:58.436+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:35:58.473+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T09:36:40.243+0000] {processor.py:161} INFO - Started process (PID=1826) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:40.245+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:36:40.249+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:36:40.249+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:40.263+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:40.295+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:36:40.294+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:36:40.311+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:36:40.311+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:36:03.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T09:36:44.904+0000] {processor.py:161} INFO - Started process (PID=1876) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:44.905+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:36:44.908+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:36:44.908+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:44.920+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:36:44.950+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:36:44.950+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:36:44.966+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:36:44.966+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:36:45.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.104 seconds
[2025-03-23T09:37:30.098+0000] {processor.py:161} INFO - Started process (PID=2026) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:37:30.100+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:37:30.103+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:37:30.103+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:37:30.116+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:37:30.142+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:37:30.141+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:37:30.157+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:37:30.157+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:37:30.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T09:38:01.167+0000] {processor.py:161} INFO - Started process (PID=2230) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:38:01.169+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:38:01.172+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:38:01.172+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:38:01.182+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:38:01.208+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:38:01.208+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:38:01.222+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:38:01.222+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:38:01.252+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T09:39:00.067+0000] {processor.py:161} INFO - Started process (PID=2284) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:39:00.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:39:00.071+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:39:00.070+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:39:00.081+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:39:00.110+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:39:00.109+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:39:00.125+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:39:00.125+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:39:00.167+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T09:40:00.148+0000] {processor.py:161} INFO - Started process (PID=2391) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:40:00.150+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:40:00.152+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:40:00.152+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:40:00.162+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:40:00.190+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:40:00.189+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:40:00.204+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:40:00.204+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:40:00.233+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T09:40:30.989+0000] {processor.py:161} INFO - Started process (PID=2618) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:40:30.991+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:40:30.994+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:40:30.993+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:40:31.007+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:40:31.027+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:40:31.026+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:40:31.042+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:40:31.042+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:40:31.063+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.078 seconds
[2025-03-23T09:41:10.474+0000] {processor.py:161} INFO - Started process (PID=2629) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:41:10.475+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:41:10.477+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:41:10.477+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:41:10.486+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:41:10.509+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:41:10.509+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:41:10.522+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:41:10.521+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:41:10.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.074 seconds
[2025-03-23T09:41:41.131+0000] {processor.py:161} INFO - Started process (PID=2785) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:41:41.133+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:41:41.136+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:41:41.135+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:41:41.149+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:41:41.185+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:41:41.184+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:41:41.210+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:41:41.209+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:41:41.254+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.129 seconds
[2025-03-23T09:42:20.559+0000] {processor.py:161} INFO - Started process (PID=2788) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:42:20.560+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:42:20.564+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:42:20.563+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:42:20.577+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:42:20.607+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:42:20.607+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:42:20.624+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:42:20.623+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:42:20.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T09:43:25.516+0000] {processor.py:161} INFO - Started process (PID=2934) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:43:25.518+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:43:25.520+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:43:25.520+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:43:25.531+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:43:25.556+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:43:25.556+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:43:25.572+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:43:25.571+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:43:25.602+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T09:43:13.217+0000] {processor.py:161} INFO - Started process (PID=53) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:43:13.219+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:43:13.221+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:43:13.220+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:43:50.512+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:43:50.543+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:43:50.543+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:43:50.560+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:43:50.560+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:43:50.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T09:44:21.376+0000] {processor.py:161} INFO - Started process (PID=254) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:21.378+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:44:21.383+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:21.383+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:21.422+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:21.448+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:21.448+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:44:21.466+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:21.465+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:44:21.497+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.127 seconds
[2025-03-23T09:45:01.032+0000] {processor.py:161} INFO - Started process (PID=261) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:23.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:44:23.834+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:23.833+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:23.850+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:23.879+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:23.879+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:44:23.894+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:23.894+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:44:23.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T09:44:54.490+0000] {processor.py:161} INFO - Started process (PID=316) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:54.499+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:44:54.508+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:54.507+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:54.524+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:44:54.558+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:54.557+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:44:54.577+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:44:54.576+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:44:54.609+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.125 seconds
[2025-03-23T09:45:25.015+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:45:25.016+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:45:25.018+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:45:25.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:45:25.050+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:45:25.079+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:45:25.079+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:45:25.095+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:45:25.095+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:45:25.120+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.110 seconds
[2025-03-23T09:46:06.020+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:46:06.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:46:06.023+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:46:06.023+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:46:06.034+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:46:06.062+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:46:06.061+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:46:06.075+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:46:06.075+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:46:06.105+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T09:46:40.897+0000] {processor.py:161} INFO - Started process (PID=516) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:46:40.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:46:40.901+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:46:40.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:46:40.913+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:46:40.941+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:46:40.940+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:46:40.956+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:46:40.956+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:46:40.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T09:47:21.029+0000] {processor.py:161} INFO - Started process (PID=665) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:47:21.031+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:47:21.034+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:47:21.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:47:21.047+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:47:21.074+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:47:21.073+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:47:21.087+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:47:21.087+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:47:21.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T09:48:26.133+0000] {processor.py:161} INFO - Started process (PID=824) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:48:26.134+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:48:26.137+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:48:26.136+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:48:26.148+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:48:26.183+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:48:26.182+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:48:26.201+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:48:26.200+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:48:26.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T09:49:01.282+0000] {processor.py:161} INFO - Started process (PID=932) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:49:01.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:49:01.287+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:49:01.286+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:49:01.302+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:49:01.333+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:49:01.332+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:49:01.355+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:49:01.354+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:49:01.389+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.113 seconds
[2025-03-23T09:49:56.837+0000] {processor.py:161} INFO - Started process (PID=1044) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:49:56.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:49:56.843+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:49:56.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:49:56.858+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:49:56.886+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:49:56.885+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:49:56.903+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:49:56.903+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:49:56.934+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T09:50:27.746+0000] {processor.py:161} INFO - Started process (PID=1101) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:50:27.748+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:50:27.750+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:50:27.750+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:50:27.762+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:50:27.789+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:50:27.788+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:50:27.810+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:50:27.810+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:50:27.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T09:51:21.911+0000] {processor.py:161} INFO - Started process (PID=1158) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:51:21.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:51:21.916+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:51:21.916+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:50:44.598+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:50:44.634+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:50:44.634+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:50:44.652+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:50:44.652+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:50:44.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.111 seconds
[2025-03-23T09:51:26.501+0000] {processor.py:161} INFO - Started process (PID=1209) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:51:26.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:51:26.506+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:51:26.506+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:51:26.517+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:51:26.545+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:51:26.545+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:51:26.560+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:51:26.560+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:51:26.597+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T09:52:16.504+0000] {processor.py:161} INFO - Started process (PID=52) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:16.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:52:16.519+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:16.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:16.582+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:16.630+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:16.630+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:52:16.649+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:16.648+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:52:16.678+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.190 seconds
[2025-03-23T09:52:51.620+0000] {processor.py:161} INFO - Started process (PID=150) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:51.622+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:52:51.625+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:51.624+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:51.639+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:51.673+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:51.672+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:52:51.693+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:51.693+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:52:51.727+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.114 seconds
[2025-03-23T09:52:59.731+0000] {processor.py:161} INFO - Started process (PID=291) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:59.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:52:59.735+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:59.735+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:59.752+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:52:59.784+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:59.783+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:52:59.811+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:52:59.810+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:52:59.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.120 seconds
[2025-03-23T09:53:41.890+0000] {processor.py:161} INFO - Started process (PID=342) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:41.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:53:41.896+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:41.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:04.673+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:04.720+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:04.719+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:53:04.740+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:04.740+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:53:04.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.136 seconds
[2025-03-23T09:53:09.740+0000] {processor.py:161} INFO - Started process (PID=393) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:09.741+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:53:09.744+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:09.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:09.759+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:09.792+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:09.792+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:53:09.811+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:09.811+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:53:09.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.122 seconds
[2025-03-23T09:53:51.634+0000] {processor.py:161} INFO - Started process (PID=454) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:51.635+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:53:51.638+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:51.638+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:51.651+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:53:51.679+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:51.678+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:53:51.696+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:53:51.695+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:53:51.730+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T09:54:36.682+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:54:36.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:54:36.686+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:54:36.686+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:54:36.697+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:54:36.723+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:54:36.723+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:54:36.739+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:54:36.739+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:54:36.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T09:55:17.590+0000] {processor.py:161} INFO - Started process (PID=695) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:55:17.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:55:17.594+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:55:17.594+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:55:17.603+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:55:17.626+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:55:17.626+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:55:17.640+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:55:17.640+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:55:17.667+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.081 seconds
[2025-03-23T09:55:52.434+0000] {processor.py:161} INFO - Started process (PID=758) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:55:52.437+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:55:52.441+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:55:52.440+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:55:52.458+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:55:52.494+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:55:52.493+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:55:52.512+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:55:52.512+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:55:52.545+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.166 seconds
[2025-03-23T09:56:47.837+0000] {processor.py:161} INFO - Started process (PID=815) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:56:47.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:56:47.842+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:56:47.841+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:56:47.855+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:56:47.886+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:56:47.885+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:56:47.907+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:56:47.907+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:56:47.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T09:57:22.203+0000] {processor.py:161} INFO - Started process (PID=878) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:57:22.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:57:22.207+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:57:22.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:57:22.218+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:57:22.247+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:57:22.246+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:56:45.012+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:56:45.011+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:56:45.049+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T09:57:27.061+0000] {processor.py:161} INFO - Started process (PID=929) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:57:27.062+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:57:27.065+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:57:27.065+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:57:27.082+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:57:27.111+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:57:27.110+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:57:27.128+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:57:27.127+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:57:27.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.104 seconds
[2025-03-23T09:58:02.758+0000] {processor.py:161} INFO - Started process (PID=1078) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:58:02.760+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:58:02.762+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:58:02.761+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:58:02.772+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:58:02.794+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:58:02.794+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:58:02.808+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:58:02.807+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:58:02.837+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.083 seconds
[2025-03-23T09:58:33.673+0000] {processor.py:161} INFO - Started process (PID=1135) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:58:33.675+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:58:33.678+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:58:33.677+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:58:33.691+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:58:33.720+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:58:33.719+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:58:33.735+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:58:33.735+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:58:33.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T09:59:37.325+0000] {processor.py:161} INFO - Started process (PID=1199) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:37.327+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:59:37.330+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:37.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:37.345+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:37.379+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:37.379+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:59:37.396+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:37.395+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:59:37.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T09:59:20.981+0000] {processor.py:161} INFO - Started process (PID=46) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:20.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:59:20.987+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:20.986+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:21.017+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:21.060+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:21.059+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:59:21.089+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:21.088+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:59:21.124+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.147 seconds
[2025-03-23T09:59:51.789+0000] {processor.py:161} INFO - Started process (PID=103) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:51.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T09:59:51.796+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:51.795+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:51.826+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T09:59:51.858+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:51.857+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T09:59:51.875+0000] {logging_mixin.py:188} INFO - [2025-03-23T09:59:51.875+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T09:59:51.907+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.126 seconds
[2025-03-23T10:00:22.019+0000] {processor.py:161} INFO - Started process (PID=157) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:00:22.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:00:22.025+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:00:22.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:00:22.039+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:00:22.069+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:00:22.068+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:00:22.083+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:00:22.083+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:00:22.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T10:01:07.520+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:01:07.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:01:07.523+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:01:07.522+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:01:07.533+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:01:07.558+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:01:07.558+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:01:07.574+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:01:07.573+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:01:07.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.088 seconds
[2025-03-23T10:02:02.611+0000] {processor.py:161} INFO - Started process (PID=400) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:02:02.612+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:02:02.615+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:02:02.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:02:02.625+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:02:02.647+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:02:02.647+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:02:02.662+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:02:02.662+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:02:02.687+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.081 seconds
[2025-03-23T10:02:47.987+0000] {processor.py:161} INFO - Started process (PID=506) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:02:47.989+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:02:47.992+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:02:47.991+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:02:48.005+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:02:48.033+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:02:48.032+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:02:48.050+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:02:48.050+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:02:48.086+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.104 seconds
[2025-03-23T10:03:18.282+0000] {processor.py:161} INFO - Started process (PID=575) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:03:18.284+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:03:18.286+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:03:18.286+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:03:18.300+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:03:18.325+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:03:18.324+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:03:18.342+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:03:18.342+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:03:18.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T10:03:58.061+0000] {processor.py:161} INFO - Started process (PID=602) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:03:58.063+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:03:58.067+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:03:58.066+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:03:58.079+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:03:58.107+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:03:58.106+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:03:58.125+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:03:58.125+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:03:58.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T10:04:28.499+0000] {processor.py:161} INFO - Started process (PID=661) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:04:28.500+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:04:28.503+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:04:28.503+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:04:28.518+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:04:28.545+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:04:28.544+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:04:28.565+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:04:28.564+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:04:28.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T10:05:08.031+0000] {processor.py:161} INFO - Started process (PID=680) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:08.032+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:05:08.034+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:08.034+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:08.044+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:08.065+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:08.064+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:05:08.079+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:08.079+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:04:30.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.079 seconds
[2025-03-23T10:05:12.974+0000] {processor.py:161} INFO - Started process (PID=731) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:12.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:05:12.979+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:12.978+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:12.990+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:13.016+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:13.016+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:05:13.031+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:13.031+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:05:13.059+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T10:05:43.418+0000] {processor.py:161} INFO - Started process (PID=837) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:43.421+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:05:43.424+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:43.424+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:43.436+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:05:43.468+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:43.467+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:05:43.483+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:05:43.483+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:05:43.518+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T10:06:43.197+0000] {processor.py:161} INFO - Started process (PID=866) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:06:43.198+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:06:43.201+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:06:43.200+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:06:43.211+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:06:43.234+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:06:43.233+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:06:43.248+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:06:43.247+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:06:43.274+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.081 seconds
[2025-03-23T10:07:13.446+0000] {processor.py:161} INFO - Started process (PID=920) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:07:13.447+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:07:13.451+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:07:13.450+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:07:13.464+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:07:13.493+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:07:13.492+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:07:13.511+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:07:13.511+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:07:13.548+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.107 seconds
[2025-03-23T10:08:19.051+0000] {processor.py:161} INFO - Started process (PID=985) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:08:19.053+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:08:19.056+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:08:19.056+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:08:19.070+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:08:19.094+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:08:19.093+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:08:19.108+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:08:19.108+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:08:19.134+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.088 seconds
[2025-03-23T10:08:53.173+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:08:53.175+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:08:53.178+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:08:53.177+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:08:53.190+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:08:53.214+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:08:53.213+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:08:53.227+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:08:53.227+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:08:53.257+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T10:09:24.242+0000] {processor.py:161} INFO - Started process (PID=1148) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:09:24.243+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:09:24.246+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:09:24.246+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:09:24.257+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:09:24.279+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:09:24.278+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:09:24.294+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:09:24.293+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:09:24.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.080 seconds
[2025-03-23T10:10:09.019+0000] {processor.py:161} INFO - Started process (PID=1162) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:10:09.024+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:10:09.028+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:10:09.027+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:10:09.048+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:10:09.081+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:10:09.080+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:10:09.115+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:10:09.115+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:10:09.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.138 seconds
[2025-03-23T10:10:40.031+0000] {processor.py:161} INFO - Started process (PID=1225) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:10:40.034+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:10:40.036+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:10:40.036+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:10:40.048+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:10:40.075+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:10:40.075+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:10:40.093+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:10:40.092+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:10:40.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T10:11:10.828+0000] {processor.py:161} INFO - Started process (PID=1282) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:11:10.830+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:11:10.832+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:11:10.832+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:11:10.843+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:11:10.868+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:11:10.867+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:11:10.881+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:11:10.881+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:11:10.912+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T10:11:48.642+0000] {processor.py:161} INFO - Started process (PID=1291) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:11:48.643+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:11:48.646+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:11:48.645+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:11:48.660+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:11:48.689+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:11:48.688+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:11:48.702+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:11:48.701+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:11:48.729+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T10:12:49.295+0000] {processor.py:161} INFO - Started process (PID=1561) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:12:49.296+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:12:49.298+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:12:49.298+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:12:49.308+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:12:49.328+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:12:49.327+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:12:49.341+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:12:49.340+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:12:49.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.074 seconds
[2025-03-23T10:13:39.403+0000] {processor.py:161} INFO - Started process (PID=1624) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:13:39.405+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:13:39.407+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:13:39.406+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:13:39.418+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:13:39.443+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:13:39.442+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:13:39.461+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:13:39.461+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:13:39.491+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T10:14:09.593+0000] {processor.py:161} INFO - Started process (PID=1687) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:14:09.595+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:14:09.599+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:14:09.598+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:14:09.613+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:14:09.637+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:14:09.636+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:14:09.651+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:14:09.651+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:14:09.682+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T10:14:48.891+0000] {processor.py:161} INFO - Started process (PID=1701) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:14:48.892+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:14:48.895+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:14:48.894+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:14:48.907+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:14:48.934+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:14:48.933+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:14:48.949+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:14:48.949+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:14:48.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T10:15:19.609+0000] {processor.py:161} INFO - Started process (PID=1857) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:15:19.611+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:15:19.615+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:15:19.614+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:15:19.629+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:15:19.658+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:15:19.658+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:15:19.673+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:15:19.672+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:15:19.705+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T10:16:04.382+0000] {processor.py:161} INFO - Started process (PID=1864) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:04.383+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:16:04.385+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:16:04.385+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:04.396+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:04.421+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:16:04.420+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:15:27.114+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:15:27.114+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:15:27.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T10:16:09.016+0000] {processor.py:161} INFO - Started process (PID=1915) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:09.018+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:16:09.023+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:16:09.022+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:09.036+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:09.061+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:16:09.060+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:16:09.078+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:16:09.078+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:16:09.113+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T10:16:39.363+0000] {processor.py:161} INFO - Started process (PID=2021) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:39.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:16:39.371+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:16:39.370+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:39.387+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:16:39.418+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:16:39.417+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:16:39.438+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:16:39.437+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:16:39.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.116 seconds
[2025-03-23T10:17:09.831+0000] {processor.py:161} INFO - Started process (PID=2084) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:17:09.832+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:17:09.835+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:17:09.834+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:17:09.848+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:17:09.873+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:17:09.873+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:17:09.893+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:17:09.893+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:17:09.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T10:17:49.182+0000] {processor.py:161} INFO - Started process (PID=2086) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:17:49.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:17:49.186+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:17:49.186+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:17:49.200+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:17:49.226+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:17:49.225+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:17:49.242+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:17:49.242+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:17:49.275+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T10:18:19.740+0000] {processor.py:161} INFO - Started process (PID=2311) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:18:19.742+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:18:19.744+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:18:19.743+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:18:19.755+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:18:19.781+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:18:19.780+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:18:19.793+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:18:19.792+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:18:19.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T10:18:59.258+0000] {processor.py:161} INFO - Started process (PID=2316) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:18:59.260+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:18:59.264+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:18:59.264+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:18:59.275+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:18:59.300+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:18:59.299+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:18:59.314+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:18:59.314+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:18:59.345+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T10:19:27.475+0000] {processor.py:161} INFO - Started process (PID=2473) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:19:27.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:19:27.481+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:19:27.480+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:19:27.496+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:19:27.533+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:19:27.533+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:19:27.560+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:19:27.560+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:19:27.621+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.149 seconds
[2025-03-23T10:19:58.079+0000] {processor.py:161} INFO - Started process (PID=2524) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:19:58.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:19:58.083+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:19:58.082+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:19:58.093+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:19:58.117+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:19:58.116+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:19:58.131+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:19:58.131+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:19:58.162+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T10:20:28.863+0000] {processor.py:161} INFO - Started process (PID=2575) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:20:28.868+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:20:28.873+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:20:28.873+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:20:28.890+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:20:28.919+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:20:28.919+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:20:28.940+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:20:28.939+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:20:28.971+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.123 seconds
[2025-03-23T10:21:09.645+0000] {processor.py:161} INFO - Started process (PID=2621) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:09.646+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:21:09.648+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:09.648+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:09.658+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:09.685+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:09.684+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:20:32.494+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:20:32.493+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:20:32.524+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T10:21:14.723+0000] {processor.py:161} INFO - Started process (PID=2667) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:14.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:21:14.728+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:14.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:14.738+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:20:37.586+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:20:37.585+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:20:37.601+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:20:37.600+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:20:37.630+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T10:21:24.880+0000] {processor.py:161} INFO - Started process (PID=2713) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:24.882+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:21:24.889+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:24.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:24.914+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:24.957+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:24.956+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:21:24.974+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:24.974+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:21:25.005+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.137 seconds
[2025-03-23T10:21:59.671+0000] {processor.py:161} INFO - Started process (PID=2815) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:59.673+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:21:59.675+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:59.675+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:59.688+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:21:59.719+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:59.718+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:21:59.739+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:21:59.739+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:21:59.769+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T10:22:59.652+0000] {processor.py:161} INFO - Started process (PID=3003) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:22:59.654+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:22:59.656+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:22:59.656+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:22:59.672+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:22:59.702+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:22:59.701+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:22:59.717+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:22:59.717+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:22:59.749+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T10:23:34.798+0000] {processor.py:161} INFO - Started process (PID=3106) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:23:34.800+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:23:34.803+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:23:34.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:23:34.814+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:23:34.836+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:23:34.836+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:23:34.849+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:23:34.848+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:23:34.879+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.084 seconds
[2025-03-23T10:24:05.151+0000] {processor.py:161} INFO - Started process (PID=3263) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:24:05.153+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:24:05.156+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:24:05.155+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:24:05.168+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:24:05.194+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:24:05.194+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:24:05.213+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:24:05.212+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:24:05.251+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.108 seconds
[2025-03-23T10:24:35.495+0000] {processor.py:161} INFO - Started process (PID=3315) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:24:35.496+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:24:35.499+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:24:35.498+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:24:35.509+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:24:35.533+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:24:35.532+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:24:35.546+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:24:35.546+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:24:35.569+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.077 seconds
[2025-03-23T10:25:15.120+0000] {processor.py:161} INFO - Started process (PID=3321) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:25:15.122+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:25:15.125+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:25:15.125+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:25:15.136+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:25:15.164+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:25:15.163+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:25:15.181+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:25:15.181+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:24:38.035+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T10:25:35.761+0000] {processor.py:161} INFO - Started process (PID=3377) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:25:35.762+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:25:35.764+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:25:35.764+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:25:35.776+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:25:35.804+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:25:35.804+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:25:35.820+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:25:35.819+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:25:35.845+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T10:26:06.649+0000] {processor.py:161} INFO - Started process (PID=3436) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:26:06.651+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:26:06.655+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:26:06.654+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:26:06.668+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:26:06.693+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:26:06.693+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:26:06.707+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:26:06.707+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:26:06.740+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T10:27:00.327+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:00.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:27:00.332+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:00.331+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:00.350+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:26:23.155+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:26:23.154+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:26:23.175+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:26:23.174+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:26:23.215+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.126 seconds
[2025-03-23T10:27:05.372+0000] {processor.py:161} INFO - Started process (PID=104) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:05.373+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:27:05.375+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:05.375+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:05.389+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:05.416+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:05.415+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:27:05.430+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:05.430+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:26:28.290+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T10:26:58.533+0000] {processor.py:161} INFO - Started process (PID=153) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:26:58.536+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:26:58.538+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:26:58.538+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:26:58.551+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:26:58.586+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:26:58.585+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:26:58.605+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:26:58.605+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:26:58.639+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.110 seconds
[2025-03-23T10:27:45.304+0000] {processor.py:161} INFO - Started process (PID=199) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:45.305+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:27:45.308+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:45.308+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:45.319+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:45.350+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:45.349+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:27:45.363+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:45.362+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:27:08.205+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T10:27:38.836+0000] {processor.py:161} INFO - Started process (PID=255) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:38.838+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:27:38.843+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:38.842+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:38.854+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:27:38.886+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:38.886+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:27:38.905+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:27:38.905+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:27:38.938+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T10:28:09.815+0000] {processor.py:161} INFO - Started process (PID=311) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:28:09.817+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:28:09.820+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:28:09.819+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:28:09.833+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:28:09.864+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:28:09.863+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:28:09.886+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:28:09.886+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:28:09.924+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.116 seconds
[2025-03-23T10:28:18.492+0000] {processor.py:161} INFO - Started process (PID=367) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:28:18.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:28:18.497+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:28:18.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:28:18.514+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:28:18.544+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:28:18.544+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:28:18.557+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:28:18.557+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:28:18.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T10:29:01.282+0000] {processor.py:161} INFO - Started process (PID=422) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:01.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:29:01.287+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:01.286+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:01.304+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:01.332+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:01.332+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:29:01.347+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:01.346+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:29:01.376+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T10:29:35.545+0000] {processor.py:161} INFO - Started process (PID=481) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:35.547+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:29:35.550+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:35.549+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:35.564+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:35.595+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:35.594+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:29:35.610+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:35.609+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:29:35.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T10:29:33.739+0000] {processor.py:161} INFO - Started process (PID=580) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:33.740+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:29:33.744+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:33.744+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:33.756+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:33.783+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:33.783+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:29:33.796+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:33.796+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:29:33.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T10:29:43.855+0000] {processor.py:161} INFO - Started process (PID=633) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:43.856+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:29:43.860+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:43.859+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:43.872+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:29:43.912+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:43.911+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:29:43.937+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:29:43.937+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:29:43.986+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.136 seconds
[2025-03-23T10:30:25.717+0000] {processor.py:161} INFO - Started process (PID=686) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:25.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:30:25.720+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:25.720+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:25.733+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:25.761+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:25.761+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:30:25.779+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:25.779+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:30:25.810+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T10:30:03.823+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:03.824+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:30:03.827+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:03.826+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:03.841+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:03.871+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:03.870+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:30:03.885+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:03.884+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:30:03.915+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T10:30:46.486+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:46.488+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:30:46.492+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:46.491+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:46.506+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:46.538+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:46.537+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:30:46.556+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:46.555+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:30:46.588+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T10:30:49.007+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:49.009+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:30:49.012+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:49.012+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:49.025+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:49.055+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:49.055+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:30:49.070+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:49.069+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:30:49.102+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T10:30:53.926+0000] {processor.py:161} INFO - Started process (PID=221) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:53.928+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:30:53.931+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:53.931+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:53.945+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:53.976+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:53.975+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:30:53.997+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:53.997+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:30:54.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.119 seconds
[2025-03-23T10:31:35.913+0000] {processor.py:161} INFO - Started process (PID=274) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:31:35.915+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:31:35.919+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:31:35.919+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:31:35.932+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:30:58.697+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:58.696+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:30:58.715+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:30:58.714+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:30:58.748+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.107 seconds
[2025-03-23T10:31:40.554+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:31:40.555+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:31:40.558+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:31:40.557+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:31:40.571+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:31:40.594+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:31:40.594+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:31:40.608+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:31:40.608+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:31:40.636+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T10:32:22.553+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:32:22.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:32:22.557+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:32:22.557+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:32:22.574+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:32:22.613+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:32:22.612+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:32:22.629+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:32:22.629+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:32:22.661+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.115 seconds
[2025-03-23T10:32:53.463+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:32:53.465+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:32:53.468+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:32:53.468+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:32:53.482+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:32:53.509+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:32:53.509+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:33:30.721+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:33:30.721+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:33:30.752+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T10:34:11.577+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:34:11.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:34:11.583+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:34:11.582+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:34:11.600+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:34:11.635+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:34:11.634+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:34:11.654+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:34:11.653+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:34:11.688+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.118 seconds
[2025-03-23T10:34:46.136+0000] {processor.py:161} INFO - Started process (PID=284) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:34:46.137+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:34:46.140+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:34:46.139+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:34:08.960+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:34:08.990+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:34:08.989+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:34:09.011+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:34:09.011+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:34:09.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T10:35:01.797+0000] {processor.py:161} INFO - Started process (PID=335) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:01.798+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:35:01.802+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:01.802+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:01.816+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:01.841+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:01.841+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:35:01.856+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:01.856+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:35:01.885+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T10:35:32.764+0000] {processor.py:161} INFO - Started process (PID=406) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:32.766+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:35:32.772+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:32.771+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:32.787+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:32.826+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:32.825+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:35:32.860+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:32.860+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:35:32.890+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.138 seconds
[2025-03-23T10:35:58.299+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:58.300+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:35:58.303+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:58.302+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:58.319+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:35:58.352+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:58.352+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:35:58.369+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:35:58.369+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:35:58.400+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T10:36:28.685+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:28.688+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:36:28.691+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:28.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:28.705+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:28.730+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:28.730+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:36:28.748+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:28.747+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:36:28.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T10:36:29.225+0000] {processor.py:161} INFO - Started process (PID=121) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:29.227+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:36:29.230+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:29.230+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:29.249+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:29.284+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:29.282+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:36:29.300+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:29.300+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:36:29.327+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T10:36:59.761+0000] {processor.py:161} INFO - Started process (PID=174) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:59.764+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:36:59.768+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:59.767+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:59.786+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:36:59.826+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:59.826+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:36:59.851+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:36:59.851+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:36:59.886+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.134 seconds
[2025-03-23T10:37:30.773+0000] {processor.py:161} INFO - Started process (PID=229) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:37:30.774+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:37:30.778+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:37:30.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:37:30.794+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:37:30.820+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:37:30.820+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:37:30.838+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:37:30.838+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:37:30.876+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T10:37:34.402+0000] {processor.py:161} INFO - Started process (PID=273) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:37:34.407+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:37:34.409+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:37:34.409+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:37:34.424+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:37:34.451+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:37:34.450+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:37:34.467+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:37:34.467+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:37:34.494+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T10:38:04.762+0000] {processor.py:161} INFO - Started process (PID=325) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:04.763+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:38:04.766+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:04.766+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:04.780+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:04.806+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:04.806+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:38:04.821+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:04.821+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:38:04.850+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T10:38:09.560+0000] {processor.py:161} INFO - Started process (PID=373) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:09.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:38:09.566+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:09.566+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:09.580+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:09.613+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:09.612+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:38:09.632+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:09.631+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:38:09.660+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T10:38:46.230+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:46.232+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:38:46.236+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:46.236+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:46.254+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:46.285+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:46.285+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:38:46.300+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:46.300+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:38:46.328+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.104 seconds
[2025-03-23T10:38:54.643+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:54.644+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:38:54.647+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:54.646+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:54.658+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:54.688+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:54.688+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:38:54.704+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:54.704+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:38:54.737+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T10:39:36.606+0000] {processor.py:161} INFO - Started process (PID=162) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:59.425+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:38:59.429+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:59.429+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:59.449+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:38:59.488+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:59.487+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:38:59.509+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:38:59.509+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:38:59.544+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.127 seconds
[2025-03-23T10:39:29.981+0000] {processor.py:161} INFO - Started process (PID=212) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:39:29.983+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:39:29.986+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:39:29.985+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:39:29.997+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:39:30.024+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:39:30.023+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:39:30.044+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:39:30.044+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:39:30.074+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T10:40:31.649+0000] {processor.py:161} INFO - Started process (PID=265) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:40:31.650+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:40:31.653+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:40:31.652+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:40:31.666+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:40:31.695+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:40:31.694+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:40:31.708+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:40:31.708+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:40:31.734+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T10:41:02.519+0000] {processor.py:161} INFO - Started process (PID=324) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:02.521+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:41:02.523+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:02.523+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:02.534+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:02.564+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:02.564+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:41:02.583+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:02.582+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:41:02.616+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T10:41:51.750+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:51.753+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:41:51.757+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:51.756+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:51.771+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:51.801+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:51.800+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:41:51.817+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:51.817+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:41:51.847+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T10:41:49.983+0000] {processor.py:161} INFO - Started process (PID=491) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:49.987+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:41:49.991+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:49.990+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:50.011+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:41:50.055+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:50.054+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:41:50.074+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:41:50.073+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:41:50.107+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.130 seconds
[2025-03-23T10:42:20.473+0000] {processor.py:161} INFO - Started process (PID=543) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:42:20.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:42:20.480+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:42:20.479+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:42:20.495+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:42:20.528+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:42:20.527+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:42:20.549+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:42:20.548+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:42:20.582+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.113 seconds
[2025-03-23T10:43:21.896+0000] {processor.py:161} INFO - Started process (PID=595) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:21.898+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:43:21.902+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:21.901+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:21.911+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:21.935+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:21.934+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:43:21.948+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:21.948+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:43:21.978+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.085 seconds
[2025-03-23T10:43:56.928+0000] {processor.py:161} INFO - Started process (PID=791) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:56.930+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:43:56.933+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:56.932+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:56.947+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:56.979+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:56.978+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:43:56.994+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:56.994+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:43:57.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T10:43:50.311+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:50.312+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:43:50.315+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:50.314+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:50.324+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:50.351+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:50.350+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:43:50.366+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:50.365+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:43:50.393+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T10:43:55.036+0000] {processor.py:161} INFO - Started process (PID=863) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:55.038+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:43:55.040+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:55.040+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:55.053+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:43:55.082+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:55.082+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:43:55.096+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:43:55.096+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:43:55.128+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T10:44:52.824+0000] {processor.py:161} INFO - Started process (PID=914) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:44:52.825+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:44:52.827+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:44:52.827+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:44:52.837+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:44:52.861+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:44:52.860+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:44:52.875+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:44:52.874+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:44:52.901+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.081 seconds
[2025-03-23T10:45:23.814+0000] {processor.py:161} INFO - Started process (PID=985) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:45:23.816+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:45:23.818+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:45:23.818+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:45:23.831+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:45:23.855+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:45:23.854+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:45:23.869+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:45:23.869+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:45:23.900+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T10:46:02.383+0000] {processor.py:161} INFO - Started process (PID=1001) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:46:02.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:46:02.387+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:46:02.387+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:46:02.399+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:46:02.429+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:46:02.428+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:46:02.448+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:46:02.448+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:46:02.479+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T10:46:07.063+0000] {processor.py:161} INFO - Started process (PID=1050) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:46:07.064+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:46:07.066+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:46:07.066+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:46:07.077+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:46:07.099+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:46:07.099+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:46:07.115+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:46:07.114+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:46:07.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.079 seconds
[2025-03-23T10:47:07.393+0000] {processor.py:161} INFO - Started process (PID=1319) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:07.395+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:47:07.397+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:07.397+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:07.408+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:07.434+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:07.434+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:47:07.446+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:07.446+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:47:07.474+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.085 seconds
[2025-03-23T10:47:42.545+0000] {processor.py:161} INFO - Started process (PID=1423) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:42.546+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:47:42.549+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:42.549+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:42.563+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:42.589+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:42.588+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:47:42.605+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:42.605+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:47:42.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T10:48:07.297+0000] {processor.py:161} INFO - Started process (PID=1514) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:07.298+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:48:07.300+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:07.300+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:07.316+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:07.350+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:07.349+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:48:07.371+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:07.371+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:48:07.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.128 seconds
[2025-03-23T10:47:58.883+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:58.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:47:58.887+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:58.887+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:58.901+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:47:58.926+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:58.926+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:47:58.942+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:47:58.941+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:47:58.969+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T10:48:42.616+0000] {processor.py:161} INFO - Started process (PID=114) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:42.617+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:48:42.621+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:42.620+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:42.636+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:42.671+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:42.670+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:48:42.696+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:42.696+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:48:42.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.123 seconds
[2025-03-23T10:48:45.624+0000] {processor.py:161} INFO - Started process (PID=256) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:45.626+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:48:45.629+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:45.628+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:45.643+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:45.671+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:45.670+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:48:45.686+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:45.686+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:48:45.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T10:48:55.945+0000] {processor.py:161} INFO - Started process (PID=309) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:55.946+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:48:55.949+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:55.948+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:55.960+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:48:55.987+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:55.987+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:48:56.000+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:48:56.000+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:48:56.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T10:50:03.317+0000] {processor.py:161} INFO - Started process (PID=368) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:50:03.319+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:50:03.322+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:50:03.322+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:50:03.335+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:50:03.365+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:50:03.364+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:50:03.380+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:50:03.380+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:50:03.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T10:50:37.769+0000] {processor.py:161} INFO - Started process (PID=427) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:50:37.770+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:50:37.772+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:50:37.772+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:50:37.783+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:50:37.806+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:50:37.805+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:50:37.819+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:50:37.819+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:50:37.841+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.076 seconds
[2025-03-23T10:51:12.857+0000] {processor.py:161} INFO - Started process (PID=538) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:51:12.858+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:51:12.860+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:51:12.860+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:51:12.873+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:51:12.903+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:51:12.902+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:51:12.918+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:51:12.918+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:51:12.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T10:52:03.022+0000] {processor.py:161} INFO - Started process (PID=771) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:03.023+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:52:03.025+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:03.025+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:03.038+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:03.066+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:03.066+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:52:03.081+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:03.081+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:52:03.110+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T10:52:07.835+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:07.836+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:52:07.839+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:07.839+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:07.852+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:07.884+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:07.883+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:52:07.902+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:07.902+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:52:07.935+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T10:52:58.103+0000] {processor.py:161} INFO - Started process (PID=931) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:58.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:52:58.109+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:58.108+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:58.123+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:52:58.149+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:58.148+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:52:20.986+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:52:20.986+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:52:21.018+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T10:53:02.861+0000] {processor.py:161} INFO - Started process (PID=981) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:02.863+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:53:02.868+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:02.867+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:02.881+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:02.909+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:02.909+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:53:02.921+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:02.921+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:53:02.950+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T10:53:43.172+0000] {processor.py:161} INFO - Started process (PID=1090) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:43.174+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:53:43.177+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:43.176+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:43.189+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:43.223+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:43.222+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:53:43.242+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:43.242+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:53:06.111+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.111 seconds
[2025-03-23T10:53:48.163+0000] {processor.py:161} INFO - Started process (PID=1140) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:48.164+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:53:48.167+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:48.166+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:48.179+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:48.209+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:48.209+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:53:48.223+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:48.222+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:53:11.094+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T10:53:52.923+0000] {processor.py:161} INFO - Started process (PID=1190) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:52.924+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:53:52.927+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:52.927+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:52.938+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:52.964+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:52.964+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:53:52.978+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:52.978+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:53:53.006+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T10:54:28.347+0000] {processor.py:161} INFO - Started process (PID=1295) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:54:28.349+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:54:28.352+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:54:28.352+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:54:28.363+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:53:51.274+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:51.273+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:53:51.292+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:53:51.292+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:53:51.326+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T10:54:33.041+0000] {processor.py:161} INFO - Started process (PID=1345) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:54:33.042+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:54:33.045+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:54:33.045+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:54:33.060+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:54:33.089+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:54:33.089+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:54:33.107+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:54:33.106+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:54:33.137+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T10:55:18.275+0000] {processor.py:161} INFO - Started process (PID=1498) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:18.277+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:55:18.280+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:18.279+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:18.294+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:18.321+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:18.321+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:55:18.335+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:18.335+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:55:18.362+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T10:55:53.476+0000] {processor.py:161} INFO - Started process (PID=1602) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:53.477+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:55:53.480+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:53.480+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:53.491+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:16.374+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:16.374+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:55:16.394+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:16.393+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:55:16.421+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T10:55:46.760+0000] {processor.py:161} INFO - Started process (PID=1658) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:46.761+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:55:46.764+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:46.764+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:46.778+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:55:46.805+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:46.805+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:55:46.822+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:55:46.822+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:55:46.862+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T10:56:34.346+0000] {processor.py:161} INFO - Started process (PID=1711) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:56:34.348+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:56:34.351+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:56:34.351+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:56:34.364+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:56:34.385+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:56:34.385+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:56:34.399+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:56:34.399+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:56:34.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.082 seconds
[2025-03-23T10:57:08.492+0000] {processor.py:161} INFO - Started process (PID=1770) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:08.493+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:57:08.496+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:08.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:08.509+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:08.535+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:08.534+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:57:08.549+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:08.548+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:57:08.574+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T10:57:21.892+0000] {processor.py:161} INFO - Started process (PID=1883) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:21.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:57:21.896+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:21.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:21.909+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:21.938+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:21.937+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:57:21.955+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:21.955+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:57:21.985+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T10:57:52.097+0000] {processor.py:161} INFO - Started process (PID=1942) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:52.099+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:57:52.101+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:52.101+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:52.114+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:52.148+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:52.147+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:57:52.165+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:52.165+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:57:52.197+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T10:58:33.722+0000] {processor.py:161} INFO - Started process (PID=1995) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:58:33.724+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:58:33.728+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:58:33.727+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:58:33.743+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:57:56.638+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:56.637+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:57:56.655+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:57:56.655+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:57:56.692+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.120 seconds
[2025-03-23T10:58:48.808+0000] {processor.py:161} INFO - Started process (PID=2049) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:58:48.810+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:58:48.813+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:58:48.813+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:58:48.827+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:58:11.745+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:58:11.744+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:58:11.764+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:58:11.764+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:58:11.794+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.108 seconds
[2025-03-23T10:59:03.489+0000] {processor.py:161} INFO - Started process (PID=2097) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:59:03.490+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:59:03.493+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:59:03.492+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:59:03.503+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:59:03.535+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:59:03.535+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:59:03.550+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:59:03.550+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:59:03.584+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T10:59:32.057+0000] {processor.py:161} INFO - Started process (PID=2257) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:59:32.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T10:59:32.063+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:59:32.062+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:59:32.083+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:59:32.118+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:59:32.118+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:59:32.138+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:59:32.138+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:59:32.173+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.122 seconds
[2025-03-23T11:00:28.875+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:28.876+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:00:28.881+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:28.881+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:59:51.743+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T10:59:51.777+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:59:51.776+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T10:59:51.792+0000] {logging_mixin.py:188} INFO - [2025-03-23T10:59:51.792+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T10:59:51.823+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T11:00:33.918+0000] {processor.py:161} INFO - Started process (PID=111) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:33.920+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:00:33.922+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:33.921+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:33.935+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:33.960+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:33.960+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:00:33.974+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:33.973+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:00:34.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T11:00:32.060+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:32.061+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:00:32.064+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:32.063+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:32.077+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:32.104+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:32.104+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:00:32.120+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:32.120+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:00:32.150+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:00:36.912+0000] {processor.py:161} INFO - Started process (PID=255) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:36.913+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:00:36.917+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:36.917+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:36.932+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:00:36.964+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:36.963+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:00:36.987+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:00:36.987+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:00:37.021+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.113 seconds
[2025-03-23T11:01:18.949+0000] {processor.py:161} INFO - Started process (PID=305) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:18.950+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:01:18.953+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:18.952+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:18.965+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:18.994+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:18.993+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:01:19.010+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:19.010+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:01:19.043+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T11:01:17.150+0000] {processor.py:161} INFO - Started process (PID=410) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:17.151+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:01:17.153+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:17.153+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:17.163+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:17.189+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:17.188+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:01:17.205+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:17.205+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:01:17.241+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:01:22.028+0000] {processor.py:161} INFO - Started process (PID=456) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:22.029+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:01:22.031+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:22.031+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:22.042+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:22.075+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:22.075+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:01:22.094+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:22.094+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:01:22.123+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T11:01:32.209+0000] {processor.py:161} INFO - Started process (PID=508) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:32.210+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:01:32.214+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:32.213+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:32.224+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:01:32.255+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:32.254+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:01:32.270+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:01:32.270+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:01:32.302+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T11:02:14.068+0000] {processor.py:161} INFO - Started process (PID=554) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:02:14.069+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:02:14.071+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:02:14.071+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:02:14.082+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:02:14.109+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:02:14.108+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:02:14.122+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:02:14.121+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:02:14.151+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T11:02:37.589+0000] {processor.py:161} INFO - Started process (PID=861) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:02:37.591+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:02:37.593+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:02:37.592+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:02:37.603+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:02:37.632+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:02:37.632+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:02:37.645+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:02:37.645+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:02:37.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T11:03:08.662+0000] {processor.py:161} INFO - Started process (PID=920) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:08.663+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:03:08.666+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:08.665+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:08.675+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:08.702+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:08.701+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:03:08.716+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:08.716+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:03:08.744+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T11:03:12.286+0000] {processor.py:161} INFO - Started process (PID=973) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:12.287+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:03:12.290+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:12.289+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:12.301+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:12.332+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:12.331+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:03:12.347+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:12.347+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:03:12.373+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T11:03:17.306+0000] {processor.py:161} INFO - Started process (PID=1018) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:17.308+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:03:17.311+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:17.310+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:17.322+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:17.346+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:17.346+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:03:17.361+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:17.361+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:03:17.395+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T11:03:47.557+0000] {processor.py:161} INFO - Started process (PID=1069) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:47.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:03:47.561+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:47.561+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:47.573+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:03:47.599+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:47.599+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:03:47.613+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:03:47.613+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:03:47.641+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.088 seconds
[2025-03-23T11:04:29.248+0000] {processor.py:161} INFO - Started process (PID=1115) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:04:29.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:04:29.253+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:04:29.252+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:04:29.265+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:04:29.290+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:04:29.290+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:04:29.306+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:04:29.306+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:04:29.331+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T11:05:14.383+0000] {processor.py:161} INFO - Started process (PID=1224) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:14.385+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:05:14.389+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:14.388+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:14.407+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:14.437+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:14.436+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:05:14.451+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:14.451+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:04:37.351+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T11:05:29.142+0000] {processor.py:161} INFO - Started process (PID=1274) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:29.144+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:05:29.148+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:29.147+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:29.162+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:29.190+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:29.190+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:05:29.203+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:29.203+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:05:29.232+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T11:05:37.483+0000] {processor.py:161} INFO - Started process (PID=1514) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:37.485+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:05:37.488+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:37.487+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:37.503+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:05:37.530+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:37.529+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:05:37.543+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:05:37.543+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:05:37.575+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T11:06:19.272+0000] {processor.py:161} INFO - Started process (PID=1564) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:06:19.273+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:06:19.276+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:06:19.276+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:06:19.291+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:06:19.321+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:06:19.321+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:06:19.337+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:06:19.337+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:06:19.366+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T11:06:49.890+0000] {processor.py:161} INFO - Started process (PID=1722) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:06:49.893+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:06:49.897+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:06:49.897+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:06:49.909+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:06:49.935+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:06:49.935+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:06:49.953+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:06:49.953+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:06:49.987+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T11:07:25.605+0000] {processor.py:161} INFO - Started process (PID=1733) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:07:25.607+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:07:25.610+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:07:25.610+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:07:25.623+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:07:25.652+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:07:25.652+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:07:25.666+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:07:25.666+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:07:25.696+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T11:07:22.755+0000] {processor.py:161} INFO - Started process (PID=1792) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:07:22.757+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:07:22.759+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:07:22.759+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:07:22.770+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:07:22.798+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:07:22.797+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:07:22.815+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:07:22.815+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:07:22.846+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T11:08:04.414+0000] {processor.py:161} INFO - Started process (PID=1849) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:04.415+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:08:04.418+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:04.418+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:04.434+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:04.460+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:04.460+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:08:04.479+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:04.478+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:08:04.514+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T11:08:12.685+0000] {processor.py:161} INFO - Started process (PID=2000) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:12.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:08:12.690+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:12.690+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:12.702+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:12.726+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:12.726+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:08:12.741+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:12.741+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:08:12.774+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:08:43.418+0000] {processor.py:161} INFO - Started process (PID=2058) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:43.419+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:08:43.421+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:43.420+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:43.432+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:43.458+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:43.457+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:08:43.471+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:43.471+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:08:43.499+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.085 seconds
[2025-03-23T11:08:47.884+0000] {processor.py:161} INFO - Started process (PID=2111) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:47.885+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:08:47.888+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:47.888+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:47.899+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:47.932+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:47.931+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:08:47.947+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:47.947+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:08:47.975+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T11:08:52.684+0000] {processor.py:161} INFO - Started process (PID=2158) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:52.685+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:08:52.689+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:52.688+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:52.703+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:08:52.729+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:52.728+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:08:52.747+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:08:52.746+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:08:52.783+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.104 seconds
[2025-03-23T11:09:34.676+0000] {processor.py:161} INFO - Started process (PID=2209) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:09:34.677+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:09:34.681+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:09:34.681+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:09:34.696+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:09:34.722+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:09:34.722+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:09:34.737+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:09:34.736+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:09:34.768+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T11:10:04.819+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:04.821+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:10:04.825+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:10:04.824+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:04.851+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:09:27.787+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:09:27.786+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:09:27.821+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:09:27.820+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:09:27.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.166 seconds
[2025-03-23T11:10:15.187+0000] {processor.py:161} INFO - Started process (PID=110) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:15.189+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:10:15.192+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:10:15.191+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:15.231+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:09:38.026+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:09:38.025+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:09:38.052+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:09:38.052+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:09:38.093+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.156 seconds
[2025-03-23T11:10:08.502+0000] {processor.py:161} INFO - Started process (PID=165) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:08.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:10:08.509+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:10:08.508+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:08.521+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:08.554+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:10:08.553+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:10:08.568+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:10:08.568+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:10:08.600+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T11:10:54.782+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:54.783+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:10:54.786+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:10:54.786+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:54.797+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:10:54.821+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:10:54.820+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:10:54.837+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:10:54.837+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:10:54.874+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T11:11:25.944+0000] {processor.py:161} INFO - Started process (PID=459) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:25.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:11:25.949+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:25.948+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:25.960+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:25.991+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:25.990+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:11:26.008+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:26.007+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:11:26.038+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T11:11:04.401+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:04.402+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:11:04.407+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:04.407+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:04.424+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:04.456+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:04.455+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:11:04.476+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:04.476+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:11:04.505+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.108 seconds
[2025-03-23T11:11:46.018+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:46.020+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:11:46.024+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:46.023+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:46.043+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:11:46.083+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:46.081+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:11:46.116+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:11:46.115+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:11:46.159+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.147 seconds
[2025-03-23T11:12:50.363+0000] {processor.py:161} INFO - Started process (PID=172) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:12:50.365+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:12:50.369+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:12:50.368+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:12:50.384+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:12:50.419+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:12:50.418+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:12:13.192+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:12:13.191+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:12:13.255+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.161 seconds
[2025-03-23T11:12:55.125+0000] {processor.py:161} INFO - Started process (PID=223) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:12:55.126+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:12:55.128+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:12:55.128+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:12:55.144+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:12:55.171+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:12:55.170+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:12:55.186+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:12:55.185+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:12:55.219+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T11:13:30.213+0000] {processor.py:161} INFO - Started process (PID=407) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:13:30.214+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:13:30.218+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:13:30.218+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:13:30.233+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:13:30.265+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:13:30.264+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:13:30.284+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:13:30.284+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:13:30.323+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.116 seconds
[2025-03-23T11:14:05.137+0000] {processor.py:161} INFO - Started process (PID=489) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:05.139+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:14:05.142+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:05.142+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:05.156+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:05.186+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:05.185+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:14:05.202+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:05.201+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:14:05.229+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T11:13:58.704+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:13:58.705+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:13:58.708+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:13:58.707+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:13:58.718+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:13:58.742+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:13:58.741+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:13:58.754+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:13:58.754+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:13:58.785+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T11:14:03.513+0000] {processor.py:161} INFO - Started process (PID=689) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:03.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:14:03.519+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:03.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:03.535+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:03.566+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:03.565+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:14:03.580+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:03.580+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:14:03.608+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T11:14:13.475+0000] {processor.py:161} INFO - Started process (PID=748) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:13.476+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:14:13.479+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:13.478+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:13.495+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:13.525+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:13.525+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:14:13.539+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:13.539+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:14:13.565+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:15:05.388+0000] {processor.py:161} INFO - Started process (PID=801) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:05.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:15:05.393+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:05.392+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:05.406+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:14:28.322+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:28.322+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:14:28.339+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:14:28.339+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:14:28.372+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.113 seconds
[2025-03-23T11:15:30.608+0000] {processor.py:161} INFO - Started process (PID=857) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:30.610+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:15:30.613+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:30.613+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:30.626+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:30.656+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:30.656+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:15:30.669+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:30.669+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:15:30.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T11:15:27.420+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:27.422+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:15:27.426+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:27.426+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:27.448+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:27.484+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:27.484+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:15:27.505+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:27.505+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:15:27.540+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.126 seconds
[2025-03-23T11:15:38.510+0000] {processor.py:161} INFO - Started process (PID=112) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:38.513+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:15:38.517+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:38.517+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:38.536+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:15:38.582+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:38.581+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:15:38.611+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:15:38.610+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:15:38.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.171 seconds
[2025-03-23T11:16:09.105+0000] {processor.py:161} INFO - Started process (PID=161) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:16:09.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:16:09.108+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:16:09.107+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:16:09.117+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:16:09.144+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:16:09.143+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:16:09.158+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:16:09.158+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:16:09.191+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T11:16:50.468+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:16:50.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:16:50.472+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:16:50.471+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:16:50.484+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:16:50.513+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:16:50.511+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:16:50.531+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:16:50.531+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:16:50.572+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.107 seconds
[2025-03-23T11:17:25.636+0000] {processor.py:161} INFO - Started process (PID=475) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:17:25.638+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:17:25.641+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:17:25.640+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:16:48.508+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:16:48.550+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:16:48.549+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:16:48.573+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:16:48.572+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:16:48.603+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.121 seconds
[2025-03-23T11:17:30.413+0000] {processor.py:161} INFO - Started process (PID=512) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:17:30.414+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:17:30.416+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:17:30.415+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:17:30.428+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:17:30.456+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:17:30.455+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:17:30.469+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:17:30.469+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:17:30.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T11:18:11.389+0000] {processor.py:161} INFO - Started process (PID=577) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:11.390+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:18:11.394+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:11.393+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:11.406+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:11.436+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:11.436+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:18:11.453+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:11.453+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:18:11.489+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T11:18:56.467+0000] {processor.py:161} INFO - Started process (PID=636) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:56.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:18:56.471+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:56.471+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:56.483+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:56.511+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:56.510+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:18:56.528+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:56.528+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:18:56.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T11:18:53.915+0000] {processor.py:161} INFO - Started process (PID=696) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:53.917+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:18:53.919+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:53.919+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:53.933+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:18:53.961+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:53.961+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:18:53.978+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:18:53.977+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:18:54.012+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T11:19:36.007+0000] {processor.py:161} INFO - Started process (PID=749) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:36.008+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:19:36.011+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:36.010+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:36.021+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:36.055+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:36.054+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:19:36.076+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:36.076+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:19:36.104+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T11:19:29.089+0000] {processor.py:161} INFO - Started process (PID=988) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:29.091+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:19:29.096+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:29.096+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:29.110+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:29.140+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:29.139+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:19:29.159+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:29.158+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:19:29.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.108 seconds
[2025-03-23T11:20:10.999+0000] {processor.py:161} INFO - Started process (PID=1042) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:20:11.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:20:11.004+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:20:11.003+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:20:11.021+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:20:11.054+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:20:11.054+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:20:11.072+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:20:11.072+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:19:33.939+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.112 seconds
[2025-03-23T11:19:48.102+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:48.103+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:19:48.106+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:48.105+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:48.119+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:19:48.148+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:48.147+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:19:48.165+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:19:48.164+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:19:48.192+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:20:55.832+0000] {processor.py:161} INFO - Started process (PID=131) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:20:55.833+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:20:55.834+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:20:55.834+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:20:55.848+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:20:55.875+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:20:55.874+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:20:55.889+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:20:55.889+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:20:55.918+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T11:21:05.182+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:21:05.184+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:21:05.188+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:21:05.187+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:21:05.206+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:21:05.246+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:21:05.246+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:21:05.266+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:21:05.265+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:21:05.294+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.118 seconds
[2025-03-23T11:21:51.025+0000] {processor.py:161} INFO - Started process (PID=150) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:21:51.027+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:21:51.029+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:21:51.028+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:21:51.041+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:21:51.070+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:21:51.069+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:21:51.086+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:21:51.086+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:21:51.114+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T11:22:21.524+0000] {processor.py:161} INFO - Started process (PID=303) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:22:21.526+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:22:21.530+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:22:21.529+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:22:21.543+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:22:21.571+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:22:21.570+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:22:21.586+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:22:21.585+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:22:21.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:22:52.406+0000] {processor.py:161} INFO - Started process (PID=354) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:22:52.409+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:22:52.411+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:22:52.411+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:22:52.422+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:22:52.450+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:22:52.449+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:22:52.467+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:22:52.467+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:22:52.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T11:23:36.174+0000] {processor.py:161} INFO - Started process (PID=398) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:23:36.176+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:23:36.180+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:23:36.179+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:23:36.193+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:23:36.223+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:23:36.222+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:23:36.239+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:23:36.239+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:23:36.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T11:23:23.332+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:23:23.334+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:23:23.337+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:23:23.337+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:23:23.351+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:23:23.386+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:23:23.385+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:23:23.403+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:23:23.403+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:23:23.428+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T11:24:06.199+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:24:06.201+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:24:06.203+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:24:06.203+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:24:06.212+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:24:06.235+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:24:06.233+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:24:06.250+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:24:06.249+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:24:06.273+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.078 seconds
[2025-03-23T11:25:11.368+0000] {processor.py:161} INFO - Started process (PID=285) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:11.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:25:11.372+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:11.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:11.384+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:11.421+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:11.420+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:25:11.439+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:11.438+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:25:11.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T11:25:46.501+0000] {processor.py:161} INFO - Started process (PID=392) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:46.503+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:25:46.505+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:46.505+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:46.517+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:46.547+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:46.547+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:25:46.564+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:46.564+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:25:46.592+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T11:25:44.677+0000] {processor.py:161} INFO - Started process (PID=494) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:44.680+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:25:44.682+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:44.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:44.694+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:44.722+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:44.722+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:25:44.737+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:44.736+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:25:44.766+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:25:49.578+0000] {processor.py:161} INFO - Started process (PID=547) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:49.579+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:25:49.581+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:49.580+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:49.593+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:25:49.618+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:49.618+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:25:49.633+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:25:49.632+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:25:49.662+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T11:26:31.558+0000] {processor.py:161} INFO - Started process (PID=600) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:26:31.559+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:26:31.562+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:26:31.562+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:26:31.574+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:26:31.604+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:26:31.603+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:26:31.617+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:26:31.617+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:26:31.645+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T11:27:02.388+0000] {processor.py:161} INFO - Started process (PID=751) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:02.389+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:27:02.392+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:02.391+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:02.403+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:02.429+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:02.429+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:27:02.443+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:02.443+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:27:02.469+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.085 seconds
[2025-03-23T11:27:14.717+0000] {processor.py:161} INFO - Started process (PID=804) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:14.718+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:27:14.721+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:14.720+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:14.734+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:14.760+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:14.759+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:27:14.775+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:14.774+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:27:14.798+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.088 seconds
[2025-03-23T11:27:56.632+0000] {processor.py:161} INFO - Started process (PID=854) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:56.634+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:27:56.636+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:56.636+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:56.649+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:56.679+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:56.679+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:27:56.699+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:56.699+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:27:56.741+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.115 seconds
[2025-03-23T11:27:36.535+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:36.537+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:27:36.540+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:36.540+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:36.555+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:27:36.584+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:36.583+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:27:36.604+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:27:36.604+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:27:36.632+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T11:28:21.837+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:28:21.839+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:28:21.845+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:28:21.844+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:28:21.869+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:28:21.919+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:28:21.916+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:28:21.946+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:28:21.946+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:27:44.858+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.153 seconds
[2025-03-23T11:28:14.963+0000] {processor.py:161} INFO - Started process (PID=158) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:28:14.970+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:28:14.972+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:28:14.972+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:28:14.986+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:28:15.005+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:28:15.004+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:28:15.017+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:28:15.017+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:28:15.037+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.080 seconds
[2025-03-23T11:29:12.601+0000] {processor.py:161} INFO - Started process (PID=206) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:12.603+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:29:12.607+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:12.606+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:12.630+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:12.679+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:12.678+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:29:12.715+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:12.715+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:29:12.758+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.163 seconds
[2025-03-23T11:29:28.627+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:28.629+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:29:28.632+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:28.631+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:28.647+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:28.675+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:28.674+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:29:28.690+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:28.690+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:29:28.714+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:29:59.364+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:59.366+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:29:59.371+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:59.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:59.392+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:29:59.427+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:59.426+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:29:59.450+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:29:59.450+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:29:59.484+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.127 seconds
[2025-03-23T11:30:29.551+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:30:29.553+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:30:29.556+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:30:29.556+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:30:29.569+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:30:29.596+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:30:29.596+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:30:29.610+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:30:29.610+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:30:29.640+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T11:31:57.115+0000] {processor.py:161} INFO - Started process (PID=280) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:31:57.116+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:31:57.119+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:31:57.119+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:31:57.131+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:31:57.160+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:31:57.159+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:31:57.179+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:31:57.178+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:31:57.208+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T11:32:36.364+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:36.367+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:32:36.372+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:36.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:36.397+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:36.442+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:36.441+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:32:36.465+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:36.464+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:32:36.498+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.140 seconds
[2025-03-23T11:32:35.573+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:35.575+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:32:35.578+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:35.577+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:35.589+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:35.619+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:35.619+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:32:35.636+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:35.636+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:32:35.663+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:32:40.204+0000] {processor.py:161} INFO - Started process (PID=160) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:40.205+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:32:40.210+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:40.209+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:40.226+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:32:40.248+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:40.248+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:32:40.263+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:32:40.262+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:32:40.293+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:33:10.919+0000] {processor.py:161} INFO - Started process (PID=217) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:33:10.921+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:33:10.926+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:33:10.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:33:10.945+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:33:10.979+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:33:10.978+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:33:11.006+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:33:11.005+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:33:11.046+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.134 seconds
[2025-03-23T11:33:52.391+0000] {processor.py:161} INFO - Started process (PID=270) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:33:52.393+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:33:52.396+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:33:52.396+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:33:52.406+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:33:52.432+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:33:52.432+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:33:52.446+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:33:52.446+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:33:52.470+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.083 seconds
[2025-03-23T11:34:20.676+0000] {processor.py:161} INFO - Started process (PID=419) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:34:20.678+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:34:20.682+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:34:20.682+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:34:20.695+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:34:20.728+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:34:20.727+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:34:20.744+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:34:20.744+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:34:20.777+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T11:34:51.367+0000] {processor.py:161} INFO - Started process (PID=478) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:34:51.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:34:51.373+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:34:51.372+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:34:51.384+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:34:51.413+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:34:51.413+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:34:51.429+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:34:51.428+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:34:51.459+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T11:35:42.503+0000] {processor.py:161} INFO - Started process (PID=537) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:42.505+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:35:42.508+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:42.507+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:42.519+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:42.548+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:42.548+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:35:42.567+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:42.567+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:35:05.480+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T11:35:47.290+0000] {processor.py:161} INFO - Started process (PID=587) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:47.291+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:35:47.293+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:47.293+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:47.306+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:47.334+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:47.334+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:35:47.352+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:47.352+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:35:47.383+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T11:35:40.888+0000] {processor.py:161} INFO - Started process (PID=777) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:40.890+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:35:40.896+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:40.895+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:40.908+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:35:40.939+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:40.939+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:35:40.961+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:35:40.961+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:35:41.001+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.118 seconds
[2025-03-23T11:36:22.775+0000] {processor.py:161} INFO - Started process (PID=821) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:22.776+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:36:22.781+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:22.779+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:22.797+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:22.835+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:22.834+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:36:22.860+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:22.859+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:35:45.735+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.140 seconds
[2025-03-23T11:36:16.037+0000] {processor.py:161} INFO - Started process (PID=868) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:16.039+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:36:16.042+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:16.042+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:16.063+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:16.090+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:16.089+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:36:16.106+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:16.106+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:36:16.138+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T11:36:20.681+0000] {processor.py:161} INFO - Started process (PID=912) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:20.683+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:36:20.686+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:20.685+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:20.700+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:20.731+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:20.730+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:36:20.747+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:20.746+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:36:20.779+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.106 seconds
[2025-03-23T11:36:30.770+0000] {processor.py:161} INFO - Started process (PID=969) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:30.771+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:36:30.774+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:30.774+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:30.790+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:36:30.816+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:30.816+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:36:30.829+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:36:30.829+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:36:30.861+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T11:37:12.580+0000] {processor.py:161} INFO - Started process (PID=1020) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:12.581+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:37:12.585+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:12.584+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:12.597+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:12.624+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:12.624+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:37:12.639+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:12.639+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:37:12.669+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T11:37:11.055+0000] {processor.py:161} INFO - Started process (PID=1128) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:11.057+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:37:11.060+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:11.060+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:11.072+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:11.103+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:11.103+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:37:11.117+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:11.117+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:37:11.146+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T11:37:52.848+0000] {processor.py:161} INFO - Started process (PID=1181) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:52.849+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:37:52.852+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:52.852+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:52.863+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:15.808+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:15.808+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:37:15.824+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:15.824+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:37:15.853+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T11:37:57.614+0000] {processor.py:161} INFO - Started process (PID=1231) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:57.616+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:37:57.620+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:57.619+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:57.629+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:37:57.651+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:57.650+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:37:57.664+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:37:57.664+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:37:57.689+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.080 seconds
[2025-03-23T11:38:27.783+0000] {processor.py:161} INFO - Started process (PID=1335) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:38:27.785+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:38:27.788+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:38:27.787+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:38:27.799+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:38:27.827+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:38:27.826+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:38:27.840+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:38:27.839+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:38:27.866+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T11:39:02.952+0000] {processor.py:161} INFO - Started process (PID=1449) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:02.953+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:39:02.955+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:02.955+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:02.966+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:02.990+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:02.990+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:39:03.003+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:03.003+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:39:03.030+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.081 seconds
[2025-03-23T11:39:11.326+0000] {processor.py:161} INFO - Started process (PID=1545) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:11.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:39:11.330+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:11.329+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:11.341+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:11.371+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:11.370+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:39:11.385+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:11.385+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:39:11.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T11:39:16.080+0000] {processor.py:161} INFO - Started process (PID=1598) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:16.081+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:39:16.083+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:16.083+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:16.095+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:16.116+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:16.116+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:39:16.131+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:16.131+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:39:16.153+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.077 seconds
[2025-03-23T11:39:57.769+0000] {processor.py:161} INFO - Started process (PID=1649) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:57.771+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:39:57.774+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:57.773+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:57.785+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:39:57.805+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:57.804+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:39:57.821+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:39:57.821+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:39:57.852+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.087 seconds
[2025-03-23T11:40:43.639+0000] {processor.py:161} INFO - Started process (PID=1804) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:40:43.641+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:40:43.644+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:40:43.644+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:40:43.655+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:40:43.683+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:40:43.682+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:40:43.699+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:40:43.699+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:40:43.732+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T11:41:23.850+0000] {processor.py:161} INFO - Started process (PID=1863) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:41:23.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:41:23.856+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:41:23.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:41:23.867+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:41:23.890+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:41:23.890+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:41:23.906+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:41:23.906+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:41:23.932+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T11:42:29.071+0000] {processor.py:161} INFO - Started process (PID=1928) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:42:29.073+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:42:29.075+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:42:29.075+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:42:29.085+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:42:29.110+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:42:29.109+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:42:29.126+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:42:29.126+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:42:29.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.089 seconds
[2025-03-23T11:43:28.399+0000] {processor.py:161} INFO - Started process (PID=1993) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:43:28.401+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:42:51.306+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:42:51.305+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:42:51.325+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:42:51.359+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:42:51.358+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:42:51.377+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:42:51.376+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:42:51.411+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.116 seconds
[2025-03-23T11:43:32.394+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:43:32.397+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:43:32.401+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:43:32.400+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:43:32.425+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:43:32.465+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:43:32.465+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:43:32.493+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:43:32.492+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:43:32.532+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.143 seconds
[2025-03-23T11:43:41.685+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:43:41.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:43:41.691+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:43:41.691+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:43:41.701+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:43:41.733+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:43:41.733+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:43:41.754+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:43:41.753+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:43:41.786+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T11:44:23.686+0000] {processor.py:161} INFO - Started process (PID=151) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:44:23.687+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:44:23.689+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:44:23.689+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:44:23.705+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:44:23.739+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:44:23.738+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:44:23.757+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:44:23.757+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:44:23.787+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T11:44:58.612+0000] {processor.py:161} INFO - Started process (PID=245) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:44:58.614+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:44:58.618+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:44:58.617+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:44:58.630+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:44:58.660+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:44:58.660+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:44:58.681+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:44:58.681+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:44:58.715+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T11:46:03.679+0000] {processor.py:161} INFO - Started process (PID=396) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:03.681+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:46:03.684+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:03.683+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:03.695+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:45:26.650+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:45:26.650+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:45:26.669+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:45:26.669+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:45:26.701+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T11:46:08.659+0000] {processor.py:161} INFO - Started process (PID=444) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:08.660+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:46:08.663+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:08.663+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:08.682+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:08.718+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:08.717+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:46:08.738+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:08.738+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:45:31.706+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.123 seconds
[2025-03-23T11:46:13.435+0000] {processor.py:161} INFO - Started process (PID=498) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:13.436+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:46:13.440+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:13.439+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:13.458+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:13.491+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:13.490+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:46:13.515+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:13.514+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:46:13.557+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.128 seconds
[2025-03-23T11:46:51.440+0000] {processor.py:161} INFO - Started process (PID=48) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:51.441+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:46:51.444+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:51.444+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:51.464+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:46:51.504+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:51.503+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:46:51.530+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:46:51.529+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:46:51.567+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.131 seconds
[2025-03-23T11:47:23.746+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:23.747+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:47:23.750+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:23.749+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:23.759+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:23.790+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:23.789+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:47:23.805+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:23.804+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:46:46.754+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.101 seconds
[2025-03-23T11:47:28.702+0000] {processor.py:161} INFO - Started process (PID=130) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:28.703+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:47:28.705+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:28.705+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:28.718+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:28.741+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:28.741+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:47:28.757+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:28.757+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:47:28.791+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T11:47:22.252+0000] {processor.py:161} INFO - Started process (PID=237) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:22.253+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:47:22.256+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:22.256+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:22.265+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:47:22.292+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:22.292+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:47:22.310+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:47:22.310+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:47:22.338+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T11:48:18.773+0000] {processor.py:161} INFO - Started process (PID=248) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:48:18.775+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:48:18.778+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:48:18.778+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:48:18.790+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:48:18.816+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:48:18.816+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:48:18.833+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:48:18.833+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:48:18.863+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T11:49:03.944+0000] {processor.py:161} INFO - Started process (PID=355) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:03.945+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:49:03.948+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:03.948+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:03.959+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:03.987+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:03.986+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:49:04.000+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:03.999+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:49:04.025+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T11:49:17.747+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:17.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:49:17.757+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:17.757+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:17.779+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:17.816+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:17.815+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:49:17.838+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:17.837+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:49:17.873+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.132 seconds
[2025-03-23T11:49:27.231+0000] {processor.py:161} INFO - Started process (PID=107) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:27.233+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:49:27.238+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:27.238+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:27.255+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:49:27.292+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:27.291+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:49:27.320+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:49:27.319+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:49:27.365+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.139 seconds
[2025-03-23T11:50:08.922+0000] {processor.py:161} INFO - Started process (PID=154) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:08.923+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:50:08.925+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:08.925+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:08.938+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:08.971+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:08.970+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:50:08.989+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:08.988+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:50:09.028+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T11:50:32.367+0000] {processor.py:161} INFO - Started process (PID=383) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:32.369+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:50:32.371+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:32.371+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:32.383+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:32.411+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:32.411+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:50:32.426+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:32.425+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:50:32.456+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T11:50:37.341+0000] {processor.py:161} INFO - Started process (PID=436) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:37.343+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:50:37.347+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:37.346+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:37.364+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:50:37.403+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:37.402+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:50:37.456+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:50:37.454+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:50:37.493+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.160 seconds
[2025-03-23T11:51:19.027+0000] {processor.py:161} INFO - Started process (PID=487) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:19.028+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:51:19.031+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:19.030+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:19.044+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:19.071+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:19.070+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:51:19.086+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:19.086+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:51:19.117+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.093 seconds
[2025-03-23T11:51:10.543+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:10.545+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:51:10.550+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:10.549+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:10.574+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:10.617+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:10.616+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:51:10.642+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:10.641+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:51:10.681+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.146 seconds
[2025-03-23T11:51:40.805+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:40.806+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:51:40.810+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:40.809+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:40.822+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:51:40.849+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:40.848+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:51:40.866+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:51:40.866+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:51:40.898+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T11:52:19.202+0000] {processor.py:161} INFO - Started process (PID=132) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:19.204+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:52:19.207+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:19.206+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:19.217+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:19.240+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:19.240+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:52:19.256+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:19.256+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:52:19.281+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.084 seconds
[2025-03-23T11:52:50.009+0000] {processor.py:161} INFO - Started process (PID=202) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:50.010+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:52:50.014+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:50.014+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:50.026+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:50.050+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:50.049+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:52:50.067+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:50.066+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:52:50.095+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T11:52:52.410+0000] {processor.py:161} INFO - Started process (PID=235) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:52.411+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:52:52.414+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:52.414+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:52.427+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:52:52.452+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:52.452+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:52:52.465+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:52:52.465+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:52:52.487+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.080 seconds
[2025-03-23T11:53:59.330+0000] {processor.py:161} INFO - Started process (PID=290) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:53:59.332+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:53:59.335+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:53:59.334+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:53:59.348+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:53:59.384+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:53:59.383+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:53:59.402+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:53:59.402+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:53:59.438+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.113 seconds
[2025-03-23T11:54:44.600+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:54:44.602+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:54:44.606+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:54:44.605+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:54:44.624+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:54:44.662+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:54:44.660+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:54:44.681+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:54:44.680+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:54:44.710+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.114 seconds
[2025-03-23T11:55:45.322+0000] {processor.py:161} INFO - Started process (PID=119) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:55:45.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:55:45.328+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:55:45.328+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:55:45.347+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:55:45.384+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:55:45.383+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:55:45.403+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:55:45.402+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:55:45.432+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.115 seconds
[2025-03-23T11:56:15.507+0000] {processor.py:161} INFO - Started process (PID=190) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:56:15.509+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:56:15.513+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:56:15.512+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:56:15.527+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:56:15.558+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:56:15.557+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:56:15.581+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:56:15.581+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:56:15.614+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.113 seconds
[2025-03-23T11:56:54.727+0000] {processor.py:161} INFO - Started process (PID=218) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:56:54.729+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:56:54.731+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:56:54.731+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:56:54.744+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:56:54.770+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:56:54.769+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:56:54.786+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:56:54.785+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:56:54.813+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T11:57:29.785+0000] {processor.py:161} INFO - Started process (PID=319) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:57:29.787+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:57:29.789+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:57:29.788+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:57:29.800+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:57:29.825+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:57:29.824+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:57:29.838+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:57:29.838+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:57:29.865+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.085 seconds
[2025-03-23T11:57:33.093+0000] {processor.py:161} INFO - Started process (PID=421) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:57:33.095+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:57:33.097+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:57:33.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:57:33.110+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:57:33.142+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:57:33.141+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:57:33.161+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:57:33.160+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:57:33.195+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.108 seconds
[2025-03-23T11:58:24.851+0000] {processor.py:161} INFO - Started process (PID=435) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:58:24.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:58:24.855+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:58:24.854+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:58:24.865+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:58:24.896+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:58:24.895+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:58:24.911+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:58:24.910+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:58:24.942+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T11:58:23.104+0000] {processor.py:161} INFO - Started process (PID=540) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:58:23.106+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:58:23.110+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:58:23.109+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:58:23.123+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:58:23.166+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:58:23.165+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:58:23.184+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:58:23.183+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:58:23.222+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.124 seconds
[2025-03-23T11:59:10.692+0000] {processor.py:161} INFO - Started process (PID=593) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:59:10.694+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:59:10.698+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:59:10.697+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:59:10.713+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:59:11.244+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:59:11.243+0000] {process_utils.py:262} INFO - Waiting up to 5 seconds for processes to exit...
[2025-03-23T11:59:23.468+0000] {processor.py:161} INFO - Started process (PID=55) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:59:23.469+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T11:59:23.473+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:59:23.472+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:59:23.487+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T11:59:23.517+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:59:23.517+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T11:59:23.533+0000] {logging_mixin.py:188} INFO - [2025-03-23T11:59:23.533+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T11:59:23.559+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T12:00:30.092+0000] {processor.py:161} INFO - Started process (PID=178) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:30.094+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:00:30.098+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:30.097+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:30.112+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:30.141+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:30.141+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:00:30.159+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:30.159+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:00:30.190+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
[2025-03-23T12:00:11.459+0000] {processor.py:161} INFO - Started process (PID=54) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:11.460+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:00:11.466+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:11.465+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:11.492+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:11.535+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:11.534+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:00:11.557+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:11.557+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:00:11.590+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.140 seconds
[2025-03-23T12:00:18.568+0000] {processor.py:161} INFO - Started process (PID=113) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:18.569+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:00:18.572+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:18.572+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:18.590+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:00:18.622+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:18.622+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:00:18.642+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:00:18.642+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:00:18.707+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.142 seconds
[2025-03-23T12:01:00.177+0000] {processor.py:161} INFO - Started process (PID=168) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:01:00.179+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:01:00.182+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:01:00.181+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:01:00.194+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:01:00.227+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:01:00.227+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:01:00.248+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:01:00.248+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:00:23.249+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T12:01:10.307+0000] {processor.py:161} INFO - Started process (PID=225) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:01:10.309+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:01:10.312+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:01:10.312+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:01:10.328+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:01:10.367+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:01:10.366+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:01:10.395+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:01:10.395+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:01:10.434+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.134 seconds
[2025-03-23T12:02:10.322+0000] {processor.py:161} INFO - Started process (PID=412) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:10.324+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:02:10.327+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:10.326+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:10.337+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:10.363+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:10.363+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:02:10.380+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:10.379+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:01:33.361+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T12:02:15.014+0000] {processor.py:161} INFO - Started process (PID=462) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:15.015+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:02:15.019+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:15.018+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:15.033+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:15.077+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:15.077+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:02:15.098+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:15.098+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:02:15.130+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.120 seconds
[2025-03-23T12:02:46.039+0000] {processor.py:161} INFO - Started process (PID=567) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:46.041+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:02:46.045+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:46.045+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:46.056+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:46.082+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:46.081+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:02:46.098+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:46.098+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:02:46.129+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T12:02:43.547+0000] {processor.py:161} INFO - Started process (PID=626) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:43.549+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:02:43.551+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:43.551+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:43.561+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:02:43.592+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:43.592+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:02:43.613+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:02:43.612+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:02:43.642+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T12:03:14.089+0000] {processor.py:161} INFO - Started process (PID=639) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:14.090+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:03:14.093+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:14.092+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:14.105+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:14.134+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:14.133+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:03:14.148+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:14.148+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:03:14.175+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T12:03:18.731+0000] {processor.py:161} INFO - Started process (PID=646) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:18.732+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:03:18.735+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:18.735+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:18.745+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:18.776+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:18.775+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:03:18.791+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:18.790+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:03:18.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T12:03:23.572+0000] {processor.py:161} INFO - Started process (PID=699) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:23.573+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:03:23.576+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:23.575+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:23.586+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:23.613+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:23.613+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:03:23.627+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:23.626+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:03:23.654+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T12:04:05.492+0000] {processor.py:161} INFO - Started process (PID=752) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:04:05.494+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:04:05.496+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:04:05.496+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:04:05.507+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:28.478+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:28.478+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:03:28.494+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:28.494+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:03:28.519+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.086 seconds
[2025-03-23T12:03:58.872+0000] {processor.py:161} INFO - Started process (PID=808) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:58.875+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:03:58.879+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:58.878+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:58.890+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:03:58.915+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:58.915+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:03:58.931+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:03:58.931+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:03:58.960+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T12:04:40.705+0000] {processor.py:161} INFO - Started process (PID=867) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:04:40.707+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:04:40.709+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:04:40.708+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:04:40.725+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:04:40.755+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:04:40.754+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:04:40.769+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:04:40.768+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:04:03.634+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.102 seconds
[2025-03-23T12:04:45.542+0000] {processor.py:161} INFO - Started process (PID=917) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:04:45.544+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:04:45.547+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:04:45.546+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:04:45.559+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:04:45.586+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:04:45.586+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:04:45.605+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:04:45.604+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:04:45.635+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.096 seconds
[2025-03-23T12:05:15.850+0000] {processor.py:161} INFO - Started process (PID=1064) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:05:15.852+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:05:15.855+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:05:15.855+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:05:15.864+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:05:15.889+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:05:15.889+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:05:15.911+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:05:15.910+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:05:15.945+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.099 seconds
[2025-03-23T12:05:46.362+0000] {processor.py:161} INFO - Started process (PID=1123) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:05:46.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:05:46.366+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:05:46.366+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:05:46.379+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:05:46.405+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:05:46.405+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:05:46.423+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:05:46.423+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:05:46.457+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.098 seconds
[2025-03-23T12:06:16.552+0000] {processor.py:161} INFO - Started process (PID=1182) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:06:16.554+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:06:16.557+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:06:16.557+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:06:16.571+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:06:16.605+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:06:16.604+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:06:16.622+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:06:16.622+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:06:16.653+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.105 seconds
[2025-03-23T12:07:15.788+0000] {processor.py:161} INFO - Started process (PID=1216) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:07:15.790+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:07:15.792+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:07:15.791+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:07:15.803+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:07:15.834+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:07:15.833+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:07:15.854+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:07:15.854+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:07:15.878+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.094 seconds
[2025-03-23T12:07:50.813+0000] {processor.py:161} INFO - Started process (PID=1319) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:07:50.815+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:07:50.817+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:07:50.817+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:07:50.828+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:07:50.860+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:07:50.858+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:07:50.877+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:07:50.877+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:07:50.910+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T12:08:31.151+0000] {processor.py:161} INFO - Started process (PID=1469) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:08:31.152+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:08:31.155+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:08:31.154+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:08:31.172+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:07:54.060+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:07:54.059+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:07:54.106+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:07:54.106+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:07:54.156+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.166 seconds
[2025-03-23T12:08:35.898+0000] {processor.py:161} INFO - Started process (PID=1519) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:08:35.900+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:08:35.903+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:08:35.902+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:08:35.914+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:08:35.944+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:08:35.943+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:08:35.961+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:08:35.961+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:08:35.993+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.100 seconds
[2025-03-23T12:09:06.065+0000] {processor.py:161} INFO - Started process (PID=1618) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:09:06.067+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:09:06.071+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:09:06.070+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:09:06.080+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:09:06.110+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:09:06.109+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:09:06.124+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:09:06.124+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:09:06.152+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.092 seconds
[2025-03-23T12:10:11.143+0000] {processor.py:161} INFO - Started process (PID=1734) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:10:11.145+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:10:11.149+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:10:11.148+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:10:11.171+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:10:11.211+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:10:11.210+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:10:11.227+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:10:11.226+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:10:11.263+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.128 seconds
[2025-03-23T12:10:56.998+0000] {processor.py:161} INFO - Started process (PID=1889) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:10:57.000+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:10:57.002+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:10:57.002+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:10:57.012+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:10:57.037+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:10:57.036+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:10:57.068+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:10:57.068+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:10:57.103+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.109 seconds
[2025-03-23T12:11:28.257+0000] {processor.py:161} INFO - Started process (PID=1954) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:11:28.258+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:11:28.260+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:11:28.260+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:11:28.270+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:11:28.405+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:11:28.405+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:11:28.423+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:11:28.422+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:11:28.454+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.202 seconds
[2025-03-23T12:12:36.327+0000] {processor.py:161} INFO - Started process (PID=2013) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:12:36.328+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:12:36.330+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:12:36.330+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:12:36.341+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:12:36.370+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:12:36.369+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:12:36.386+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:12:36.385+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:12:36.412+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.090 seconds
[2025-03-23T12:12:29.560+0000] {processor.py:161} INFO - Started process (PID=2194) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:12:29.562+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:12:29.564+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:12:29.564+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:12:29.575+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:12:29.602+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:12:29.601+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:12:29.620+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:12:29.619+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:12:29.652+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.097 seconds
[2025-03-23T12:13:11.337+0000] {processor.py:161} INFO - Started process (PID=2243) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:13:11.338+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:13:11.340+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:13:11.340+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:13:11.350+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:13:11.376+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:13:11.376+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:13:11.391+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:13:11.390+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:13:11.425+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T12:13:46.428+0000] {processor.py:161} INFO - Started process (PID=2341) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:13:46.430+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:13:46.433+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:13:46.432+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:13:46.442+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:13:46.470+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:13:46.469+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:13:46.486+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:13:46.486+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:13:46.515+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T12:14:21.804+0000] {processor.py:161} INFO - Started process (PID=2447) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:21.805+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:14:21.808+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:21.807+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:21.820+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:21.846+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:21.845+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:14:21.858+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:21.857+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:14:21.884+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.084 seconds
[2025-03-23T12:14:27.058+0000] {processor.py:161} INFO - Started process (PID=2497) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:27.059+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:14:27.061+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:27.061+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:27.070+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:27.093+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:27.092+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:14:27.104+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:27.104+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:14:27.126+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.073 seconds
[2025-03-23T12:14:57.635+0000] {processor.py:161} INFO - Started process (PID=2556) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:57.637+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:14:57.640+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:57.639+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:57.651+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:14:57.673+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:57.673+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:14:57.686+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:14:57.686+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:14:57.712+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.080 seconds
[2025-03-23T12:15:32.513+0000] {processor.py:161} INFO - Started process (PID=2615) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:15:32.515+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:15:32.518+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:15:32.518+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:15:32.531+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:15:32.560+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:15:32.559+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:15:32.576+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:15:32.575+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:15:32.604+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.095 seconds
[2025-03-23T12:16:03.572+0000] {processor.py:161} INFO - Started process (PID=2680) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:16:03.574+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:16:03.576+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:16:03.576+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:16:03.588+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:16:03.614+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:16:03.614+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:16:03.630+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:16:03.630+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:16:03.659+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.091 seconds
[2025-03-23T12:16:41.724+0000] {processor.py:161} INFO - Started process (PID=2699) to work on /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:16:41.725+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/load_csv_to_bq.py for tasks to queue
[2025-03-23T12:16:41.728+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:16:41.728+0000] {dagbag.py:540} INFO - Filling up the DagBag from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:16:41.740+0000] {processor.py:840} INFO - DAG(s) 'load_csv_to_bq' retrieved from /opt/airflow/dags/load_csv_to_bq.py
[2025-03-23T12:16:41.770+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:16:41.769+0000] {dag.py:3047} INFO - Sync 1 DAGs
[2025-03-23T12:16:41.789+0000] {logging_mixin.py:188} INFO - [2025-03-23T12:16:41.789+0000] {dag.py:3834} INFO - Setting next_dagrun for load_csv_to_bq to None, run_after=None
[2025-03-23T12:16:41.821+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/load_csv_to_bq.py took 0.103 seconds
